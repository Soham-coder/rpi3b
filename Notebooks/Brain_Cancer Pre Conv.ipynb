{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Brain_Cancer Pre Conv.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1CADFaXDwKBdLn4ZbkvIlBEplfLtGkt36","authorship_tag":"ABX9TyMyR6YWtYGh7ileXwWvTEkh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gEc34oSsYuDj","executionInfo":{"status":"ok","timestamp":1607891864137,"user_tz":-330,"elapsed":2974,"user":{"displayName":"Arindam Majee","photoUrl":"","userId":"08922294135040060764"}},"outputId":"c5b2307d-69be-4c9f-c8bf-3daba6f0bf03"},"source":["#!pip3 install tensorflow==2.3.0\n","%tensorflow_version 2.x\n","import tensorflow as tf\n","print(tf.__version__)\n","print(tf.keras.__version__)\n","\n","from tensorflow.keras.layers import Input, InputLayer, Dense, Flatten, Conv2D,Activation, BatchNormalization\n","from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler\n","from tensorflow.keras.optimizers import Adam, RMSprop\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.layers import MaxPooling2D\n","from sklearn.preprocessing import OneHotEncoder\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.models import  Model\n","import matplotlib.pyplot as plt\n","from tensorflow import keras\n","import pandas as pd\n","import numpy as np\n","import os, cv2\n","import random\n","import scipy"],"execution_count":1,"outputs":[{"output_type":"stream","text":["2.3.0\n","2.4.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YQr6hcl4Zef1","executionInfo":{"status":"ok","timestamp":1607891867331,"user_tz":-330,"elapsed":6158,"user":{"displayName":"Arindam Majee","photoUrl":"","userId":"08922294135040060764"}},"outputId":"81946c8b-16f2-4a51-b690-d9678e7288a8"},"source":["train_data = '/content/drive/MyDrive/Colab_Dataset/Brain Cancer/Train Data'\n","\n","def read_image(im_path):\n","  img = cv2.imread(im_path,0)\n","  img = cv2.resize(img,(240,240))\n","  return img\n","\n","x_train, y_train = [],[]\n","list_folder=os.listdir(path = train_data)\n","encoder = OneHotEncoder()\n","for i in list_folder:\n","  new_path = os.path.join(train_data,i) \n","  pic_list = os.listdir(new_path)                                         \n","  for img in pic_list:  \n","    im_path = os.path.join(new_path,img)\n","    image = read_image(im_path)\n","    if i == 'flair':\n","      label = 0\n","    elif i == 't1':\n","      label = 1\n","    elif i == 't1ce':\n","      label = 2\n","    elif i == 't2':\n","      label = 3\n","    x_train.append(image) \n","    y_train.append(label)\n","\n","X_train = np.array(x_train).reshape(-1,240,240,1)\n","X_train = X_train/255\n","y_train = np.array(y_train).reshape(-1,1)\n","y_train = encoder.fit_transform(y_train)\n","Y_train = y_train.toarray()\n","print(\"Train images reading is done\")\n","\n","test_data = '/content/drive/MyDrive/Colab_Dataset/Brain Cancer/Test Data for RPi'\n","x_test, y_test = [], []\n","list_folder=os.listdir(path = test_data)\n","for i in list_folder:\n","  new_path=os.path.join(test_data,i) \n","  pic_list=os.listdir(new_path)                                              \n","  for img in pic_list:  \n","    im_path = os.path.join(new_path,img)\n","    image = read_image(im_path)\n","    if i == 'flair':\n","      label = 0\n","    elif i == 't1':\n","      label = 1\n","    elif i == 't1ce':\n","      label = 2\n","    elif i == 't2':\n","      label = 3\n","    x_test.append(image) \n","    y_test.append(label) \n","\n","print(\"Test images reading is done\")\n","X_test = np.array(x_test).reshape(-1,240,240,1)\n","X_test = X_test/255\n","y_test = np.array(y_test).reshape(-1,1)\n","y_test = encoder.fit_transform(y_test)\n","Y_test = y_test.toarray()"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Train images reading is done\n","Test images reading is done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bnhpeRIhZejH","executionInfo":{"status":"ok","timestamp":1607891867332,"user_tz":-330,"elapsed":6151,"user":{"displayName":"Arindam Majee","photoUrl":"","userId":"08922294135040060764"}},"outputId":"a08ca0c6-071a-4cb6-b8f7-fbe8c0dbf97b"},"source":["train_labels = np.argmax(Y_train, axis=-1)\n","flair_class = 0\n","t1_class = 0\n","t1ce_class = 0 \n","t2_class = 0\n","\n","for i in range(len(train_labels)):\n","  if train_labels[i] == 0:\n","    flair_class += 1\n","  elif train_labels[i] == 1:\n","    t1_class += 1\n","  elif train_labels[i] == 2:\n","    t1ce_class += 1\n","  elif train_labels[i] == 3:\n","    t2_class += 1\n","\n","\n","if flair_class + t1_class + t1ce_class + t2_class == X_train.shape[0]:\n","  print('Everything is okay.')\n","  print('No of flair_class in Train set: ',flair_class)\n","  print('No of t1_class in Train set: ',t1_class)\n","  print('No of t1ce_class in Train set: ',t1ce_class)\n","  print('No of t2_class in Train set: ',t2_class)\n","else:\n","  print(\"Something is wrong!\")"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Everything is okay.\n","No of flair_class in Train set:  189\n","No of t1_class in Train set:  206\n","No of t1ce_class in Train set:  184\n","No of t2_class in Train set:  190\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yF7_52E7ZemW","executionInfo":{"status":"ok","timestamp":1607891867333,"user_tz":-330,"elapsed":6145,"user":{"displayName":"Arindam Majee","photoUrl":"","userId":"08922294135040060764"}},"outputId":"1aa0ea05-9cb8-462b-a3b1-25672f51852a"},"source":["weight_for_flair = (flair_class + t1_class + t1ce_class + t2_class)/(4.0*flair_class)\n","weight_for_t1 = (flair_class + t1_class + t1ce_class + t2_class)/(4*t1_class)\n","weight_for_t1ce = (flair_class + t1_class + t1ce_class + t2_class)/(4*t1ce_class)\n","weight_for_t2 = (flair_class + t1_class + t1ce_class + t2_class)/(4*t2_class)\n","\n","class_weight = {0: weight_for_flair, 1: weight_for_t1, 2: weight_for_t1ce, 3: weight_for_t2}\n","print('Weight for class 0: {:.2f}'.format(weight_for_flair))\n","print('Weight for class 1: {:.2f}'.format(weight_for_t1))\n","print('Weight for class 2: {:.2f}'.format(weight_for_t1ce))\n","print('Weight for class 3: {:.2f}'.format(weight_for_t2))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Weight for class 0: 1.02\n","Weight for class 1: 0.93\n","Weight for class 2: 1.04\n","Weight for class 3: 1.01\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bXG1I7EwZepm","executionInfo":{"status":"ok","timestamp":1607891867781,"user_tz":-330,"elapsed":6586,"user":{"displayName":"Arindam Majee","photoUrl":"","userId":"08922294135040060764"}},"outputId":"110cdaaa-f2ff-4c1d-e158-88d0cef03d9b"},"source":["from tensorflow.keras.layers import BatchNormalization, AveragePooling2D\n","\n","opt1 = Adam(learning_rate = 0.001)\n","opt2 = Adam(learning_rate = 0.002)\n","opt3 = Adam(learning_rate = 0.0005)\n","opt4 = RMSprop(learning_rate = 0.002)\n","opt5 = RMSprop(learning_rate = 0.0005)\n","opt6 = RMSprop(learning_rate = 0.0015)\n","\n","\n","inputShape=(240,240,1)\n","input1 = Input(inputShape)\n","x = Conv2D(1,(16,16),strides=(3,3),activation='relu', padding='same')(input1)\n","x = Conv2D(4,(3,3), name='layer_conv1', activation = 'relu', padding='same')(x)\n","x = Conv2D(8,(3,3), name='layer_conv2', activation = 'relu', padding='same')(x)\n","x = MaxPooling2D((2,2), name = 'max_pool1', padding='same')(x)\n","x = Conv2D(16,(3,3), name='layer_conv3', activation = 'relu', padding='same')(x)\n","x = Conv2D(32,(3,3), name='layer_conv4', activation = 'relu', padding='same')(x)\n","x = MaxPooling2D((2,2), name = 'max_pool2', padding='same')(x)\n","x = Conv2D(64,(3,3), name='layer_conv5', activation = 'relu')(x)\n","x = MaxPooling2D((2,2), name = 'max_pool5', padding='same')(x)\n","x = Conv2D(128,(3,3), name='layer_conv6', activation = 'relu')(x)\n","x = MaxPooling2D((2,2), name = 'max_pool6', padding='same')(x)\n","x = Flatten()(x)\n","x = Dense(64,activation = 'relu',name='fc0')(x)\n","x = Dropout(0.2)(x)\n","x = Dense(32,activation = 'relu',name='fc1')(x)\n","x = Dropout(0.2)(x)\n","x = Dense(32,activation = 'relu',name='fc2')(x)\n","x = Dropout(0.25)(x)\n","x = Dense(4, activation = 'softmax',name='op')(x)\n","classifier = Model(inputs = input1, outputs = x, name = 'Predict')\n","classifier.compile(optimizer = RMSprop(1e-4) , loss = 'categorical_crossentropy', metrics = ['accuracy'])\n","\n","classifier.summary()"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Model: \"Predict\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 240, 240, 1)]     0         \n","_________________________________________________________________\n","conv2d (Conv2D)              (None, 80, 80, 1)         257       \n","_________________________________________________________________\n","layer_conv1 (Conv2D)         (None, 80, 80, 4)         40        \n","_________________________________________________________________\n","layer_conv2 (Conv2D)         (None, 80, 80, 8)         296       \n","_________________________________________________________________\n","max_pool1 (MaxPooling2D)     (None, 40, 40, 8)         0         \n","_________________________________________________________________\n","layer_conv3 (Conv2D)         (None, 40, 40, 16)        1168      \n","_________________________________________________________________\n","layer_conv4 (Conv2D)         (None, 40, 40, 32)        4640      \n","_________________________________________________________________\n","max_pool2 (MaxPooling2D)     (None, 20, 20, 32)        0         \n","_________________________________________________________________\n","layer_conv5 (Conv2D)         (None, 18, 18, 64)        18496     \n","_________________________________________________________________\n","max_pool5 (MaxPooling2D)     (None, 9, 9, 64)          0         \n","_________________________________________________________________\n","layer_conv6 (Conv2D)         (None, 7, 7, 128)         73856     \n","_________________________________________________________________\n","max_pool6 (MaxPooling2D)     (None, 4, 4, 128)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 2048)              0         \n","_________________________________________________________________\n","fc0 (Dense)                  (None, 64)                131136    \n","_________________________________________________________________\n","dropout (Dropout)            (None, 64)                0         \n","_________________________________________________________________\n","fc1 (Dense)                  (None, 32)                2080      \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 32)                0         \n","_________________________________________________________________\n","fc2 (Dense)                  (None, 32)                1056      \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 32)                0         \n","_________________________________________________________________\n","op (Dense)                   (None, 4)                 132       \n","=================================================================\n","Total params: 233,157\n","Trainable params: 233,157\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4bMgwmzoZesc","executionInfo":{"status":"ok","timestamp":1607892102516,"user_tz":-330,"elapsed":241314,"user":{"displayName":"Arindam Majee","photoUrl":"","userId":"08922294135040060764"}},"outputId":"84fc4579-fb1a-4c31-d6e5-009e720e55ea"},"source":["PreConv_checkpoint = ModelCheckpoint(\"/content/drive/MyDrive/Colab_Dataset/Brain Cancer/v3/PreConv.h5\", monitor='val_accuracy', verbose=1,\n","    save_best_only=True, mode='auto', period=1)\n","history = classifier.fit(X_train, Y_train, batch_size = 8, epochs = 300, class_weight=class_weight,\n","                         validation_data=(X_test, Y_test), callbacks=[PreConv_checkpoint])"],"execution_count":6,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/300\n","97/97 [==============================] - ETA: 0s - loss: 1.3860 - accuracy: 0.2640\n","Epoch 00001: val_accuracy improved from -inf to 0.29534, saving model to /content/drive/MyDrive/Colab_Dataset/Brain Cancer/v3/PreConv.h5\n","97/97 [==============================] - 2s 19ms/step - loss: 1.3860 - accuracy: 0.2640 - val_loss: 1.3827 - val_accuracy: 0.2953\n","Epoch 2/300\n","92/97 [===========================>..] - ETA: 0s - loss: 1.3827 - accuracy: 0.2962\n","Epoch 00002: val_accuracy did not improve from 0.29534\n","97/97 [==============================] - 1s 7ms/step - loss: 1.3830 - accuracy: 0.2913 - val_loss: 1.3708 - val_accuracy: 0.2953\n","Epoch 3/300\n","96/97 [============================>.] - ETA: 0s - loss: 1.3682 - accuracy: 0.3203\n","Epoch 00003: val_accuracy improved from 0.29534 to 0.54404, saving model to /content/drive/MyDrive/Colab_Dataset/Brain Cancer/v3/PreConv.h5\n","97/97 [==============================] - 1s 8ms/step - loss: 1.3689 - accuracy: 0.3199 - val_loss: 1.3344 - val_accuracy: 0.5440\n","Epoch 4/300\n","97/97 [==============================] - ETA: 0s - loss: 1.3415 - accuracy: 0.3706\n","Epoch 00004: val_accuracy did not improve from 0.54404\n","97/97 [==============================] - 1s 7ms/step - loss: 1.3415 - accuracy: 0.3706 - val_loss: 1.2795 - val_accuracy: 0.4145\n","Epoch 5/300\n","97/97 [==============================] - ETA: 0s - loss: 1.2983 - accuracy: 0.4031\n","Epoch 00005: val_accuracy did not improve from 0.54404\n","97/97 [==============================] - 1s 7ms/step - loss: 1.2983 - accuracy: 0.4031 - val_loss: 1.1759 - val_accuracy: 0.4974\n","Epoch 6/300\n","94/97 [============================>.] - ETA: 0s - loss: 1.2480 - accuracy: 0.4295\n","Epoch 00006: val_accuracy did not improve from 0.54404\n","97/97 [==============================] - 1s 7ms/step - loss: 1.2466 - accuracy: 0.4343 - val_loss: 1.1083 - val_accuracy: 0.5440\n","Epoch 7/300\n","95/97 [============================>.] - ETA: 0s - loss: 1.1890 - accuracy: 0.4776\n","Epoch 00007: val_accuracy did not improve from 0.54404\n","97/97 [==============================] - 1s 7ms/step - loss: 1.1863 - accuracy: 0.4798 - val_loss: 1.0753 - val_accuracy: 0.4870\n","Epoch 8/300\n","97/97 [==============================] - ETA: 0s - loss: 1.1447 - accuracy: 0.4928\n","Epoch 00008: val_accuracy did not improve from 0.54404\n","97/97 [==============================] - 1s 7ms/step - loss: 1.1447 - accuracy: 0.4928 - val_loss: 1.0484 - val_accuracy: 0.5285\n","Epoch 9/300\n","92/97 [===========================>..] - ETA: 0s - loss: 1.1192 - accuracy: 0.5095\n","Epoch 00009: val_accuracy improved from 0.54404 to 0.58549, saving model to /content/drive/MyDrive/Colab_Dataset/Brain Cancer/v3/PreConv.h5\n","97/97 [==============================] - 1s 8ms/step - loss: 1.1233 - accuracy: 0.5072 - val_loss: 0.9763 - val_accuracy: 0.5855\n","Epoch 10/300\n","95/97 [============================>.] - ETA: 0s - loss: 1.0697 - accuracy: 0.5342\n","Epoch 00010: val_accuracy did not improve from 0.58549\n","97/97 [==============================] - 1s 8ms/step - loss: 1.0694 - accuracy: 0.5345 - val_loss: 0.9567 - val_accuracy: 0.5751\n","Epoch 11/300\n","97/97 [==============================] - ETA: 0s - loss: 1.0417 - accuracy: 0.5709\n","Epoch 00011: val_accuracy improved from 0.58549 to 0.62176, saving model to /content/drive/MyDrive/Colab_Dataset/Brain Cancer/v3/PreConv.h5\n","97/97 [==============================] - 1s 8ms/step - loss: 1.0417 - accuracy: 0.5709 - val_loss: 0.9252 - val_accuracy: 0.6218\n","Epoch 12/300\n","97/97 [==============================] - ETA: 0s - loss: 1.0039 - accuracy: 0.6060\n","Epoch 00012: val_accuracy improved from 0.62176 to 0.66321, saving model to /content/drive/MyDrive/Colab_Dataset/Brain Cancer/v3/PreConv.h5\n","97/97 [==============================] - 1s 8ms/step - loss: 1.0039 - accuracy: 0.6060 - val_loss: 0.8563 - val_accuracy: 0.6632\n","Epoch 13/300\n","96/97 [============================>.] - ETA: 0s - loss: 0.9708 - accuracy: 0.6081\n","Epoch 00013: val_accuracy did not improve from 0.66321\n","97/97 [==============================] - 1s 7ms/step - loss: 0.9725 - accuracy: 0.6073 - val_loss: 0.8099 - val_accuracy: 0.6477\n","Epoch 14/300\n","89/97 [==========================>...] - ETA: 0s - loss: 0.9134 - accuracy: 0.6433\n","Epoch 00014: val_accuracy did not improve from 0.66321\n","97/97 [==============================] - 1s 7ms/step - loss: 0.9170 - accuracy: 0.6398 - val_loss: 0.9022 - val_accuracy: 0.6425\n","Epoch 15/300\n","90/97 [==========================>...] - ETA: 0s - loss: 0.9025 - accuracy: 0.6486\n","Epoch 00015: val_accuracy improved from 0.66321 to 0.68912, saving model to /content/drive/MyDrive/Colab_Dataset/Brain Cancer/v3/PreConv.h5\n","97/97 [==============================] - 1s 8ms/step - loss: 0.9041 - accuracy: 0.6450 - val_loss: 0.7938 - val_accuracy: 0.6891\n","Epoch 16/300\n","96/97 [============================>.] - ETA: 0s - loss: 0.8570 - accuracy: 0.6758\n","Epoch 00016: val_accuracy improved from 0.68912 to 0.72021, saving model to /content/drive/MyDrive/Colab_Dataset/Brain Cancer/v3/PreConv.h5\n","97/97 [==============================] - 1s 8ms/step - loss: 0.8586 - accuracy: 0.6749 - val_loss: 0.7090 - val_accuracy: 0.7202\n","Epoch 17/300\n","93/97 [===========================>..] - ETA: 0s - loss: 0.8270 - accuracy: 0.6761\n","Epoch 00017: val_accuracy improved from 0.72021 to 0.75648, saving model to /content/drive/MyDrive/Colab_Dataset/Brain Cancer/v3/PreConv.h5\n","97/97 [==============================] - 1s 8ms/step - loss: 0.8290 - accuracy: 0.6736 - val_loss: 0.7006 - val_accuracy: 0.7565\n","Epoch 18/300\n","97/97 [==============================] - ETA: 0s - loss: 0.7895 - accuracy: 0.7009\n","Epoch 00018: val_accuracy did not improve from 0.75648\n","97/97 [==============================] - 1s 7ms/step - loss: 0.7895 - accuracy: 0.7009 - val_loss: 0.6873 - val_accuracy: 0.7150\n","Epoch 19/300\n","92/97 [===========================>..] - ETA: 0s - loss: 0.7408 - accuracy: 0.7011\n","Epoch 00019: val_accuracy did not improve from 0.75648\n","97/97 [==============================] - 1s 7ms/step - loss: 0.7456 - accuracy: 0.6983 - val_loss: 0.7328 - val_accuracy: 0.6684\n","Epoch 20/300\n","96/97 [============================>.] - ETA: 0s - loss: 0.7498 - accuracy: 0.7188\n","Epoch 00020: val_accuracy did not improve from 0.75648\n","97/97 [==============================] - 1s 7ms/step - loss: 0.7518 - accuracy: 0.7178 - val_loss: 0.7243 - val_accuracy: 0.6995\n","Epoch 21/300\n","96/97 [============================>.] - ETA: 0s - loss: 0.7478 - accuracy: 0.7109\n","Epoch 00021: val_accuracy improved from 0.75648 to 0.81347, saving model to /content/drive/MyDrive/Colab_Dataset/Brain Cancer/v3/PreConv.h5\n","97/97 [==============================] - 1s 8ms/step - loss: 0.7486 - accuracy: 0.7100 - val_loss: 0.6012 - val_accuracy: 0.8135\n","Epoch 22/300\n","97/97 [==============================] - ETA: 0s - loss: 0.6880 - accuracy: 0.7412\n","Epoch 00022: val_accuracy did not improve from 0.81347\n","97/97 [==============================] - 1s 7ms/step - loss: 0.6880 - accuracy: 0.7412 - val_loss: 0.5908 - val_accuracy: 0.7772\n","Epoch 23/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.6460 - accuracy: 0.7447\n","Epoch 00023: val_accuracy did not improve from 0.81347\n","97/97 [==============================] - 1s 7ms/step - loss: 0.6455 - accuracy: 0.7438 - val_loss: 0.6949 - val_accuracy: 0.6839\n","Epoch 24/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.6495 - accuracy: 0.7526\n","Epoch 00024: val_accuracy improved from 0.81347 to 0.84456, saving model to /content/drive/MyDrive/Colab_Dataset/Brain Cancer/v3/PreConv.h5\n","97/97 [==============================] - 1s 8ms/step - loss: 0.6509 - accuracy: 0.7516 - val_loss: 0.4672 - val_accuracy: 0.8446\n","Epoch 25/300\n","96/97 [============================>.] - ETA: 0s - loss: 0.6109 - accuracy: 0.7812\n","Epoch 00025: val_accuracy did not improve from 0.84456\n","97/97 [==============================] - 1s 7ms/step - loss: 0.6119 - accuracy: 0.7802 - val_loss: 0.8742 - val_accuracy: 0.6062\n","Epoch 26/300\n","92/97 [===========================>..] - ETA: 0s - loss: 0.6296 - accuracy: 0.7867\n","Epoch 00026: val_accuracy did not improve from 0.84456\n","97/97 [==============================] - 1s 7ms/step - loss: 0.6324 - accuracy: 0.7867 - val_loss: 0.5837 - val_accuracy: 0.7720\n","Epoch 27/300\n","93/97 [===========================>..] - ETA: 0s - loss: 0.5997 - accuracy: 0.7823\n","Epoch 00027: val_accuracy did not improve from 0.84456\n","97/97 [==============================] - 1s 7ms/step - loss: 0.5977 - accuracy: 0.7828 - val_loss: 0.5670 - val_accuracy: 0.7876\n","Epoch 28/300\n","93/97 [===========================>..] - ETA: 0s - loss: 0.5793 - accuracy: 0.7809\n","Epoch 00028: val_accuracy did not improve from 0.84456\n","97/97 [==============================] - 1s 7ms/step - loss: 0.5727 - accuracy: 0.7828 - val_loss: 0.5653 - val_accuracy: 0.8083\n","Epoch 29/300\n","93/97 [===========================>..] - ETA: 0s - loss: 0.5491 - accuracy: 0.8199\n","Epoch 00029: val_accuracy did not improve from 0.84456\n","97/97 [==============================] - 1s 7ms/step - loss: 0.5537 - accuracy: 0.8166 - val_loss: 0.5749 - val_accuracy: 0.7772\n","Epoch 30/300\n","93/97 [===========================>..] - ETA: 0s - loss: 0.5243 - accuracy: 0.8011\n","Epoch 00030: val_accuracy did not improve from 0.84456\n","97/97 [==============================] - 1s 7ms/step - loss: 0.5253 - accuracy: 0.8010 - val_loss: 0.5472 - val_accuracy: 0.7824\n","Epoch 31/300\n","93/97 [===========================>..] - ETA: 0s - loss: 0.5052 - accuracy: 0.8159\n","Epoch 00031: val_accuracy improved from 0.84456 to 0.88083, saving model to /content/drive/MyDrive/Colab_Dataset/Brain Cancer/v3/PreConv.h5\n","97/97 [==============================] - 1s 8ms/step - loss: 0.5094 - accuracy: 0.8114 - val_loss: 0.4011 - val_accuracy: 0.8808\n","Epoch 32/300\n","97/97 [==============================] - ETA: 0s - loss: 0.5378 - accuracy: 0.8114\n","Epoch 00032: val_accuracy did not improve from 0.88083\n","97/97 [==============================] - 1s 7ms/step - loss: 0.5378 - accuracy: 0.8114 - val_loss: 0.4176 - val_accuracy: 0.8653\n","Epoch 33/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.5095 - accuracy: 0.8311\n","Epoch 00033: val_accuracy improved from 0.88083 to 0.89637, saving model to /content/drive/MyDrive/Colab_Dataset/Brain Cancer/v3/PreConv.h5\n","97/97 [==============================] - 1s 8ms/step - loss: 0.5034 - accuracy: 0.8336 - val_loss: 0.3519 - val_accuracy: 0.8964\n","Epoch 34/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.4808 - accuracy: 0.8351\n","Epoch 00034: val_accuracy did not improve from 0.89637\n","97/97 [==============================] - 1s 7ms/step - loss: 0.4866 - accuracy: 0.8309 - val_loss: 0.4018 - val_accuracy: 0.8549\n","Epoch 35/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.4793 - accuracy: 0.8395\n","Epoch 00035: val_accuracy improved from 0.89637 to 0.90674, saving model to /content/drive/MyDrive/Colab_Dataset/Brain Cancer/v3/PreConv.h5\n","97/97 [==============================] - 1s 8ms/step - loss: 0.4757 - accuracy: 0.8414 - val_loss: 0.3691 - val_accuracy: 0.9067\n","Epoch 36/300\n","93/97 [===========================>..] - ETA: 0s - loss: 0.4636 - accuracy: 0.8602\n","Epoch 00036: val_accuracy did not improve from 0.90674\n","97/97 [==============================] - 1s 7ms/step - loss: 0.4672 - accuracy: 0.8557 - val_loss: 0.6991 - val_accuracy: 0.6943\n","Epoch 37/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.4455 - accuracy: 0.8592\n","Epoch 00037: val_accuracy did not improve from 0.90674\n","97/97 [==============================] - 1s 7ms/step - loss: 0.4451 - accuracy: 0.8583 - val_loss: 0.3882 - val_accuracy: 0.8549\n","Epoch 38/300\n","92/97 [===========================>..] - ETA: 0s - loss: 0.4348 - accuracy: 0.8478\n","Epoch 00038: val_accuracy did not improve from 0.90674\n","97/97 [==============================] - 1s 7ms/step - loss: 0.4304 - accuracy: 0.8479 - val_loss: 0.3414 - val_accuracy: 0.8756\n","Epoch 39/300\n","90/97 [==========================>...] - ETA: 0s - loss: 0.4328 - accuracy: 0.8403\n","Epoch 00039: val_accuracy did not improve from 0.90674\n","97/97 [==============================] - 1s 7ms/step - loss: 0.4411 - accuracy: 0.8388 - val_loss: 0.3254 - val_accuracy: 0.8653\n","Epoch 40/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.4181 - accuracy: 0.8513\n","Epoch 00040: val_accuracy did not improve from 0.90674\n","97/97 [==============================] - 1s 7ms/step - loss: 0.4249 - accuracy: 0.8505 - val_loss: 0.3808 - val_accuracy: 0.8497\n","Epoch 41/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.3875 - accuracy: 0.8579\n","Epoch 00041: val_accuracy did not improve from 0.90674\n","97/97 [==============================] - 1s 7ms/step - loss: 0.3920 - accuracy: 0.8557 - val_loss: 0.6572 - val_accuracy: 0.7306\n","Epoch 42/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.3915 - accuracy: 0.8644\n","Epoch 00042: val_accuracy did not improve from 0.90674\n","97/97 [==============================] - 1s 7ms/step - loss: 0.3856 - accuracy: 0.8661 - val_loss: 0.3647 - val_accuracy: 0.8808\n","Epoch 43/300\n","92/97 [===========================>..] - ETA: 0s - loss: 0.3480 - accuracy: 0.8845\n","Epoch 00043: val_accuracy did not improve from 0.90674\n","97/97 [==============================] - 1s 7ms/step - loss: 0.3545 - accuracy: 0.8830 - val_loss: 0.5086 - val_accuracy: 0.8083\n","Epoch 44/300\n","90/97 [==========================>...] - ETA: 0s - loss: 0.3687 - accuracy: 0.8903\n","Epoch 00044: val_accuracy did not improve from 0.90674\n","97/97 [==============================] - 1s 7ms/step - loss: 0.3901 - accuracy: 0.8869 - val_loss: 0.3239 - val_accuracy: 0.8705\n","Epoch 45/300\n","96/97 [============================>.] - ETA: 0s - loss: 0.3532 - accuracy: 0.8867\n","Epoch 00045: val_accuracy did not improve from 0.90674\n","97/97 [==============================] - 1s 7ms/step - loss: 0.3528 - accuracy: 0.8869 - val_loss: 0.2834 - val_accuracy: 0.8912\n","Epoch 46/300\n","96/97 [============================>.] - ETA: 0s - loss: 0.3313 - accuracy: 0.8932\n","Epoch 00046: val_accuracy did not improve from 0.90674\n","97/97 [==============================] - 1s 7ms/step - loss: 0.3318 - accuracy: 0.8934 - val_loss: 0.4534 - val_accuracy: 0.8446\n","Epoch 47/300\n","96/97 [============================>.] - ETA: 0s - loss: 0.3347 - accuracy: 0.8854\n","Epoch 00047: val_accuracy did not improve from 0.90674\n","97/97 [==============================] - 1s 7ms/step - loss: 0.3344 - accuracy: 0.8856 - val_loss: 0.2861 - val_accuracy: 0.8964\n","Epoch 48/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.2921 - accuracy: 0.9003\n","Epoch 00048: val_accuracy did not improve from 0.90674\n","97/97 [==============================] - 1s 7ms/step - loss: 0.2905 - accuracy: 0.8999 - val_loss: 0.2693 - val_accuracy: 0.8964\n","Epoch 49/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.3189 - accuracy: 0.8870\n","Epoch 00049: val_accuracy did not improve from 0.90674\n","97/97 [==============================] - 1s 7ms/step - loss: 0.3143 - accuracy: 0.8895 - val_loss: 0.2681 - val_accuracy: 0.8808\n","Epoch 50/300\n","89/97 [==========================>...] - ETA: 0s - loss: 0.3218 - accuracy: 0.8904\n","Epoch 00050: val_accuracy did not improve from 0.90674\n","97/97 [==============================] - 1s 7ms/step - loss: 0.3165 - accuracy: 0.8934 - val_loss: 0.2842 - val_accuracy: 0.8860\n","Epoch 51/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.3060 - accuracy: 0.9053\n","Epoch 00051: val_accuracy did not improve from 0.90674\n","97/97 [==============================] - 1s 7ms/step - loss: 0.3038 - accuracy: 0.9064 - val_loss: 0.4436 - val_accuracy: 0.8394\n","Epoch 52/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.2806 - accuracy: 0.9000\n","Epoch 00052: val_accuracy did not improve from 0.90674\n","97/97 [==============================] - 1s 7ms/step - loss: 0.2792 - accuracy: 0.8999 - val_loss: 0.2646 - val_accuracy: 0.9016\n","Epoch 53/300\n","91/97 [===========================>..] - ETA: 0s - loss: 0.2949 - accuracy: 0.9080\n","Epoch 00053: val_accuracy did not improve from 0.90674\n","97/97 [==============================] - 1s 7ms/step - loss: 0.2924 - accuracy: 0.9090 - val_loss: 0.4108 - val_accuracy: 0.8549\n","Epoch 54/300\n","89/97 [==========================>...] - ETA: 0s - loss: 0.2510 - accuracy: 0.9101\n","Epoch 00054: val_accuracy did not improve from 0.90674\n","97/97 [==============================] - 1s 7ms/step - loss: 0.2602 - accuracy: 0.9103 - val_loss: 0.2697 - val_accuracy: 0.8912\n","Epoch 55/300\n","90/97 [==========================>...] - ETA: 0s - loss: 0.2921 - accuracy: 0.9125\n","Epoch 00055: val_accuracy did not improve from 0.90674\n","97/97 [==============================] - 1s 7ms/step - loss: 0.2907 - accuracy: 0.9142 - val_loss: 0.3949 - val_accuracy: 0.8653\n","Epoch 56/300\n","92/97 [===========================>..] - ETA: 0s - loss: 0.2676 - accuracy: 0.9144\n","Epoch 00056: val_accuracy did not improve from 0.90674\n","97/97 [==============================] - 1s 7ms/step - loss: 0.2631 - accuracy: 0.9168 - val_loss: 0.3051 - val_accuracy: 0.8808\n","Epoch 57/300\n","91/97 [===========================>..] - ETA: 0s - loss: 0.2408 - accuracy: 0.9231\n","Epoch 00057: val_accuracy did not improve from 0.90674\n","97/97 [==============================] - 1s 7ms/step - loss: 0.2364 - accuracy: 0.9246 - val_loss: 0.2821 - val_accuracy: 0.8964\n","Epoch 58/300\n","91/97 [===========================>..] - ETA: 0s - loss: 0.2366 - accuracy: 0.9148\n","Epoch 00058: val_accuracy did not improve from 0.90674\n","97/97 [==============================] - 1s 7ms/step - loss: 0.2372 - accuracy: 0.9155 - val_loss: 0.2816 - val_accuracy: 0.8964\n","Epoch 59/300\n","92/97 [===========================>..] - ETA: 0s - loss: 0.2236 - accuracy: 0.9375\n","Epoch 00059: val_accuracy did not improve from 0.90674\n","97/97 [==============================] - 1s 7ms/step - loss: 0.2383 - accuracy: 0.9337 - val_loss: 0.5483 - val_accuracy: 0.8083\n","Epoch 60/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.2331 - accuracy: 0.9303\n","Epoch 00060: val_accuracy did not improve from 0.90674\n","97/97 [==============================] - 1s 7ms/step - loss: 0.2326 - accuracy: 0.9298 - val_loss: 0.4018 - val_accuracy: 0.8497\n","Epoch 61/300\n","96/97 [============================>.] - ETA: 0s - loss: 0.2382 - accuracy: 0.9245\n","Epoch 00061: val_accuracy did not improve from 0.90674\n","97/97 [==============================] - 1s 7ms/step - loss: 0.2407 - accuracy: 0.9233 - val_loss: 0.2863 - val_accuracy: 0.9016\n","Epoch 62/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.2449 - accuracy: 0.9269\n","Epoch 00062: val_accuracy improved from 0.90674 to 0.91192, saving model to /content/drive/MyDrive/Colab_Dataset/Brain Cancer/v3/PreConv.h5\n","97/97 [==============================] - 2s 16ms/step - loss: 0.2443 - accuracy: 0.9259 - val_loss: 0.2530 - val_accuracy: 0.9119\n","Epoch 63/300\n","91/97 [===========================>..] - ETA: 0s - loss: 0.2229 - accuracy: 0.9272\n","Epoch 00063: val_accuracy did not improve from 0.91192\n","97/97 [==============================] - 1s 8ms/step - loss: 0.2179 - accuracy: 0.9285 - val_loss: 0.3491 - val_accuracy: 0.8860\n","Epoch 64/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.2185 - accuracy: 0.9329\n","Epoch 00064: val_accuracy did not improve from 0.91192\n","97/97 [==============================] - 1s 8ms/step - loss: 0.2184 - accuracy: 0.9324 - val_loss: 0.2368 - val_accuracy: 0.8860\n","Epoch 65/300\n","97/97 [==============================] - ETA: 0s - loss: 0.2336 - accuracy: 0.9233\n","Epoch 00065: val_accuracy did not improve from 0.91192\n","97/97 [==============================] - 1s 7ms/step - loss: 0.2336 - accuracy: 0.9233 - val_loss: 0.2177 - val_accuracy: 0.9067\n","Epoch 66/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.1830 - accuracy: 0.9395\n","Epoch 00066: val_accuracy did not improve from 0.91192\n","97/97 [==============================] - 1s 7ms/step - loss: 0.1850 - accuracy: 0.9389 - val_loss: 0.2850 - val_accuracy: 0.8860\n","Epoch 67/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.2242 - accuracy: 0.9242\n","Epoch 00067: val_accuracy did not improve from 0.91192\n","97/97 [==============================] - 1s 7ms/step - loss: 0.2281 - accuracy: 0.9220 - val_loss: 0.2832 - val_accuracy: 0.8860\n","Epoch 68/300\n","96/97 [============================>.] - ETA: 0s - loss: 0.2010 - accuracy: 0.9362\n","Epoch 00068: val_accuracy did not improve from 0.91192\n","97/97 [==============================] - 1s 8ms/step - loss: 0.2008 - accuracy: 0.9363 - val_loss: 0.2245 - val_accuracy: 0.9119\n","Epoch 69/300\n","93/97 [===========================>..] - ETA: 0s - loss: 0.1992 - accuracy: 0.9355\n","Epoch 00069: val_accuracy did not improve from 0.91192\n","97/97 [==============================] - 1s 7ms/step - loss: 0.1959 - accuracy: 0.9363 - val_loss: 0.2620 - val_accuracy: 0.8964\n","Epoch 70/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.1752 - accuracy: 0.9348\n","Epoch 00070: val_accuracy did not improve from 0.91192\n","97/97 [==============================] - 1s 7ms/step - loss: 0.1776 - accuracy: 0.9324 - val_loss: 0.3464 - val_accuracy: 0.8860\n","Epoch 71/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.1796 - accuracy: 0.9495\n","Epoch 00071: val_accuracy did not improve from 0.91192\n","97/97 [==============================] - 1s 7ms/step - loss: 0.1798 - accuracy: 0.9493 - val_loss: 0.2437 - val_accuracy: 0.8912\n","Epoch 72/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.1771 - accuracy: 0.9455\n","Epoch 00072: val_accuracy did not improve from 0.91192\n","97/97 [==============================] - 1s 7ms/step - loss: 0.1787 - accuracy: 0.9428 - val_loss: 0.2981 - val_accuracy: 0.8860\n","Epoch 73/300\n","90/97 [==========================>...] - ETA: 0s - loss: 0.1606 - accuracy: 0.9542\n","Epoch 00073: val_accuracy improved from 0.91192 to 0.92228, saving model to /content/drive/MyDrive/Colab_Dataset/Brain Cancer/v3/PreConv.h5\n","97/97 [==============================] - 1s 15ms/step - loss: 0.1638 - accuracy: 0.9532 - val_loss: 0.2201 - val_accuracy: 0.9223\n","Epoch 74/300\n","93/97 [===========================>..] - ETA: 0s - loss: 0.1965 - accuracy: 0.9409\n","Epoch 00074: val_accuracy did not improve from 0.92228\n","97/97 [==============================] - 1s 8ms/step - loss: 0.1950 - accuracy: 0.9415 - val_loss: 0.3257 - val_accuracy: 0.8912\n","Epoch 75/300\n","93/97 [===========================>..] - ETA: 0s - loss: 0.1523 - accuracy: 0.9368\n","Epoch 00075: val_accuracy did not improve from 0.92228\n","97/97 [==============================] - 1s 7ms/step - loss: 0.1611 - accuracy: 0.9337 - val_loss: 0.2259 - val_accuracy: 0.9119\n","Epoch 76/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.1506 - accuracy: 0.9553\n","Epoch 00076: val_accuracy improved from 0.92228 to 0.92746, saving model to /content/drive/MyDrive/Colab_Dataset/Brain Cancer/v3/PreConv.h5\n","97/97 [==============================] - 1s 8ms/step - loss: 0.1510 - accuracy: 0.9558 - val_loss: 0.2410 - val_accuracy: 0.9275\n","Epoch 77/300\n","93/97 [===========================>..] - ETA: 0s - loss: 0.1391 - accuracy: 0.9624\n","Epoch 00077: val_accuracy did not improve from 0.92746\n","97/97 [==============================] - 1s 7ms/step - loss: 0.1430 - accuracy: 0.9584 - val_loss: 0.2627 - val_accuracy: 0.9171\n","Epoch 78/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.1696 - accuracy: 0.9495\n","Epoch 00078: val_accuracy did not improve from 0.92746\n","97/97 [==============================] - 1s 7ms/step - loss: 0.1697 - accuracy: 0.9493 - val_loss: 0.2294 - val_accuracy: 0.9275\n","Epoch 79/300\n","91/97 [===========================>..] - ETA: 0s - loss: 0.1334 - accuracy: 0.9574\n","Epoch 00079: val_accuracy did not improve from 0.92746\n","97/97 [==============================] - 1s 7ms/step - loss: 0.1394 - accuracy: 0.9558 - val_loss: 0.2768 - val_accuracy: 0.8860\n","Epoch 80/300\n","96/97 [============================>.] - ETA: 0s - loss: 0.1295 - accuracy: 0.9492\n","Epoch 00080: val_accuracy did not improve from 0.92746\n","97/97 [==============================] - 1s 7ms/step - loss: 0.1293 - accuracy: 0.9493 - val_loss: 0.2273 - val_accuracy: 0.9119\n","Epoch 81/300\n","93/97 [===========================>..] - ETA: 0s - loss: 0.1452 - accuracy: 0.9503\n","Epoch 00081: val_accuracy did not improve from 0.92746\n","97/97 [==============================] - 1s 7ms/step - loss: 0.1406 - accuracy: 0.9519 - val_loss: 0.2292 - val_accuracy: 0.9223\n","Epoch 82/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.1353 - accuracy: 0.9526\n","Epoch 00082: val_accuracy did not improve from 0.92746\n","97/97 [==============================] - 1s 7ms/step - loss: 0.1352 - accuracy: 0.9519 - val_loss: 0.2253 - val_accuracy: 0.9223\n","Epoch 83/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.1459 - accuracy: 0.9500\n","Epoch 00083: val_accuracy did not improve from 0.92746\n","97/97 [==============================] - 1s 8ms/step - loss: 0.1446 - accuracy: 0.9506 - val_loss: 0.2531 - val_accuracy: 0.9119\n","Epoch 84/300\n","96/97 [============================>.] - ETA: 0s - loss: 0.1298 - accuracy: 0.9609\n","Epoch 00084: val_accuracy did not improve from 0.92746\n","97/97 [==============================] - 1s 8ms/step - loss: 0.1297 - accuracy: 0.9610 - val_loss: 0.2406 - val_accuracy: 0.9067\n","Epoch 85/300\n","93/97 [===========================>..] - ETA: 0s - loss: 0.1329 - accuracy: 0.9543\n","Epoch 00085: val_accuracy did not improve from 0.92746\n","97/97 [==============================] - 1s 8ms/step - loss: 0.1322 - accuracy: 0.9545 - val_loss: 0.2250 - val_accuracy: 0.9171\n","Epoch 86/300\n","96/97 [============================>.] - ETA: 0s - loss: 0.1168 - accuracy: 0.9622\n","Epoch 00086: val_accuracy did not improve from 0.92746\n","97/97 [==============================] - 1s 8ms/step - loss: 0.1166 - accuracy: 0.9623 - val_loss: 0.2580 - val_accuracy: 0.9223\n","Epoch 87/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.1471 - accuracy: 0.9487\n","Epoch 00087: val_accuracy did not improve from 0.92746\n","97/97 [==============================] - 1s 8ms/step - loss: 0.1455 - accuracy: 0.9493 - val_loss: 0.2343 - val_accuracy: 0.9067\n","Epoch 88/300\n","96/97 [============================>.] - ETA: 0s - loss: 0.1016 - accuracy: 0.9674\n","Epoch 00088: val_accuracy improved from 0.92746 to 0.93264, saving model to /content/drive/MyDrive/Colab_Dataset/Brain Cancer/v3/PreConv.h5\n","97/97 [==============================] - 1s 15ms/step - loss: 0.1015 - accuracy: 0.9675 - val_loss: 0.1989 - val_accuracy: 0.9326\n","Epoch 89/300\n","96/97 [============================>.] - ETA: 0s - loss: 0.1156 - accuracy: 0.9609\n","Epoch 00089: val_accuracy did not improve from 0.93264\n","97/97 [==============================] - 1s 8ms/step - loss: 0.1154 - accuracy: 0.9610 - val_loss: 0.1980 - val_accuracy: 0.9275\n","Epoch 90/300\n","92/97 [===========================>..] - ETA: 0s - loss: 0.0969 - accuracy: 0.9647\n","Epoch 00090: val_accuracy did not improve from 0.93264\n","97/97 [==============================] - 1s 8ms/step - loss: 0.1045 - accuracy: 0.9623 - val_loss: 0.2238 - val_accuracy: 0.9275\n","Epoch 91/300\n","91/97 [===========================>..] - ETA: 0s - loss: 0.1173 - accuracy: 0.9602\n","Epoch 00091: val_accuracy did not improve from 0.93264\n","97/97 [==============================] - 1s 7ms/step - loss: 0.1218 - accuracy: 0.9584 - val_loss: 0.3282 - val_accuracy: 0.8912\n","Epoch 92/300\n","93/97 [===========================>..] - ETA: 0s - loss: 0.0981 - accuracy: 0.9745\n","Epoch 00092: val_accuracy did not improve from 0.93264\n","97/97 [==============================] - 1s 7ms/step - loss: 0.1032 - accuracy: 0.9727 - val_loss: 0.2803 - val_accuracy: 0.8912\n","Epoch 93/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.1205 - accuracy: 0.9526\n","Epoch 00093: val_accuracy did not improve from 0.93264\n","97/97 [==============================] - 1s 8ms/step - loss: 0.1209 - accuracy: 0.9532 - val_loss: 0.3674 - val_accuracy: 0.8705\n","Epoch 94/300\n","96/97 [============================>.] - ETA: 0s - loss: 0.1189 - accuracy: 0.9609\n","Epoch 00094: val_accuracy did not improve from 0.93264\n","97/97 [==============================] - 1s 7ms/step - loss: 0.1188 - accuracy: 0.9610 - val_loss: 0.2276 - val_accuracy: 0.9223\n","Epoch 95/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.1050 - accuracy: 0.9681\n","Epoch 00095: val_accuracy improved from 0.93264 to 0.93782, saving model to /content/drive/MyDrive/Colab_Dataset/Brain Cancer/v3/PreConv.h5\n","97/97 [==============================] - 1s 8ms/step - loss: 0.1033 - accuracy: 0.9688 - val_loss: 0.2374 - val_accuracy: 0.9378\n","Epoch 96/300\n","90/97 [==========================>...] - ETA: 0s - loss: 0.0864 - accuracy: 0.9694\n","Epoch 00096: val_accuracy did not improve from 0.93782\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0840 - accuracy: 0.9701 - val_loss: 0.2578 - val_accuracy: 0.8964\n","Epoch 97/300\n","93/97 [===========================>..] - ETA: 0s - loss: 0.0999 - accuracy: 0.9556\n","Epoch 00097: val_accuracy did not improve from 0.93782\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0983 - accuracy: 0.9571 - val_loss: 0.2849 - val_accuracy: 0.8860\n","Epoch 98/300\n","92/97 [===========================>..] - ETA: 0s - loss: 0.0987 - accuracy: 0.9701\n","Epoch 00098: val_accuracy did not improve from 0.93782\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0959 - accuracy: 0.9714 - val_loss: 0.2828 - val_accuracy: 0.8912\n","Epoch 99/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.0825 - accuracy: 0.9763\n","Epoch 00099: val_accuracy did not improve from 0.93782\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0816 - accuracy: 0.9766 - val_loss: 0.2748 - val_accuracy: 0.9016\n","Epoch 100/300\n","93/97 [===========================>..] - ETA: 0s - loss: 0.0944 - accuracy: 0.9651\n","Epoch 00100: val_accuracy improved from 0.93782 to 0.94301, saving model to /content/drive/MyDrive/Colab_Dataset/Brain Cancer/v3/PreConv.h5\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0935 - accuracy: 0.9649 - val_loss: 0.2268 - val_accuracy: 0.9430\n","Epoch 101/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.0728 - accuracy: 0.9761\n","Epoch 00101: val_accuracy did not improve from 0.94301\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0726 - accuracy: 0.9766 - val_loss: 0.2332 - val_accuracy: 0.9275\n","Epoch 102/300\n","91/97 [===========================>..] - ETA: 0s - loss: 0.0754 - accuracy: 0.9712\n","Epoch 00102: val_accuracy did not improve from 0.94301\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0839 - accuracy: 0.9649 - val_loss: 0.1975 - val_accuracy: 0.9378\n","Epoch 103/300\n","93/97 [===========================>..] - ETA: 0s - loss: 0.0764 - accuracy: 0.9745\n","Epoch 00103: val_accuracy did not improve from 0.94301\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0761 - accuracy: 0.9740 - val_loss: 0.1989 - val_accuracy: 0.9326\n","Epoch 104/300\n","93/97 [===========================>..] - ETA: 0s - loss: 0.0914 - accuracy: 0.9758\n","Epoch 00104: val_accuracy did not improve from 0.94301\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0914 - accuracy: 0.9753 - val_loss: 0.2306 - val_accuracy: 0.9119\n","Epoch 105/300\n","90/97 [==========================>...] - ETA: 0s - loss: 0.0680 - accuracy: 0.9792\n","Epoch 00105: val_accuracy did not improve from 0.94301\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0715 - accuracy: 0.9766 - val_loss: 0.3156 - val_accuracy: 0.9016\n","Epoch 106/300\n","92/97 [===========================>..] - ETA: 0s - loss: 0.0733 - accuracy: 0.9755\n","Epoch 00106: val_accuracy did not improve from 0.94301\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0707 - accuracy: 0.9766 - val_loss: 0.2418 - val_accuracy: 0.9326\n","Epoch 107/300\n","97/97 [==============================] - ETA: 0s - loss: 0.0829 - accuracy: 0.9753\n","Epoch 00107: val_accuracy did not improve from 0.94301\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0829 - accuracy: 0.9753 - val_loss: 0.3436 - val_accuracy: 0.8912\n","Epoch 108/300\n","90/97 [==========================>...] - ETA: 0s - loss: 0.0732 - accuracy: 0.9764\n","Epoch 00108: val_accuracy did not improve from 0.94301\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0702 - accuracy: 0.9779 - val_loss: 0.2785 - val_accuracy: 0.9223\n","Epoch 109/300\n","90/97 [==========================>...] - ETA: 0s - loss: 0.0464 - accuracy: 0.9806\n","Epoch 00109: val_accuracy did not improve from 0.94301\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0556 - accuracy: 0.9779 - val_loss: 0.2383 - val_accuracy: 0.9378\n","Epoch 110/300\n","93/97 [===========================>..] - ETA: 0s - loss: 0.0721 - accuracy: 0.9745\n","Epoch 00110: val_accuracy did not improve from 0.94301\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0721 - accuracy: 0.9740 - val_loss: 0.3139 - val_accuracy: 0.9016\n","Epoch 111/300\n","92/97 [===========================>..] - ETA: 0s - loss: 0.0574 - accuracy: 0.9823\n","Epoch 00111: val_accuracy did not improve from 0.94301\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0613 - accuracy: 0.9805 - val_loss: 0.3767 - val_accuracy: 0.9326\n","Epoch 112/300\n","90/97 [==========================>...] - ETA: 0s - loss: 0.0697 - accuracy: 0.9792\n","Epoch 00112: val_accuracy did not improve from 0.94301\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0657 - accuracy: 0.9805 - val_loss: 0.2366 - val_accuracy: 0.9378\n","Epoch 113/300\n","90/97 [==========================>...] - ETA: 0s - loss: 0.0636 - accuracy: 0.9806\n","Epoch 00113: val_accuracy did not improve from 0.94301\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0607 - accuracy: 0.9818 - val_loss: 0.2853 - val_accuracy: 0.9378\n","Epoch 114/300\n","90/97 [==========================>...] - ETA: 0s - loss: 0.0730 - accuracy: 0.9750\n","Epoch 00114: val_accuracy did not improve from 0.94301\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0707 - accuracy: 0.9753 - val_loss: 0.2783 - val_accuracy: 0.9378\n","Epoch 115/300\n","91/97 [===========================>..] - ETA: 0s - loss: 0.0560 - accuracy: 0.9753\n","Epoch 00115: val_accuracy did not improve from 0.94301\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0537 - accuracy: 0.9766 - val_loss: 0.2512 - val_accuracy: 0.9326\n","Epoch 116/300\n","92/97 [===========================>..] - ETA: 0s - loss: 0.0764 - accuracy: 0.9810\n","Epoch 00116: val_accuracy did not improve from 0.94301\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0740 - accuracy: 0.9818 - val_loss: 0.2817 - val_accuracy: 0.9326\n","Epoch 117/300\n","89/97 [==========================>...] - ETA: 0s - loss: 0.0418 - accuracy: 0.9817\n","Epoch 00117: val_accuracy did not improve from 0.94301\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0410 - accuracy: 0.9818 - val_loss: 0.2647 - val_accuracy: 0.9275\n","Epoch 118/300\n","96/97 [============================>.] - ETA: 0s - loss: 0.0782 - accuracy: 0.9766\n","Epoch 00118: val_accuracy did not improve from 0.94301\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0782 - accuracy: 0.9766 - val_loss: 0.2442 - val_accuracy: 0.9430\n","Epoch 119/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.0619 - accuracy: 0.9774\n","Epoch 00119: val_accuracy did not improve from 0.94301\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0608 - accuracy: 0.9779 - val_loss: 0.2662 - val_accuracy: 0.9326\n","Epoch 120/300\n","91/97 [===========================>..] - ETA: 0s - loss: 0.0364 - accuracy: 0.9890\n","Epoch 00120: val_accuracy did not improve from 0.94301\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0393 - accuracy: 0.9883 - val_loss: 0.3195 - val_accuracy: 0.9275\n","Epoch 121/300\n","93/97 [===========================>..] - ETA: 0s - loss: 0.0476 - accuracy: 0.9892\n","Epoch 00121: val_accuracy did not improve from 0.94301\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0476 - accuracy: 0.9896 - val_loss: 0.2580 - val_accuracy: 0.9223\n","Epoch 122/300\n","97/97 [==============================] - ETA: 0s - loss: 0.0681 - accuracy: 0.9727\n","Epoch 00122: val_accuracy did not improve from 0.94301\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0681 - accuracy: 0.9727 - val_loss: 0.2291 - val_accuracy: 0.9326\n","Epoch 123/300\n","91/97 [===========================>..] - ETA: 0s - loss: 0.0419 - accuracy: 0.9849\n","Epoch 00123: val_accuracy did not improve from 0.94301\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0426 - accuracy: 0.9844 - val_loss: 0.3410 - val_accuracy: 0.9223\n","Epoch 124/300\n","92/97 [===========================>..] - ETA: 0s - loss: 0.0356 - accuracy: 0.9851\n","Epoch 00124: val_accuracy improved from 0.94301 to 0.94819, saving model to /content/drive/MyDrive/Colab_Dataset/Brain Cancer/v3/PreConv.h5\n","97/97 [==============================] - 2s 17ms/step - loss: 0.0341 - accuracy: 0.9857 - val_loss: 0.2987 - val_accuracy: 0.9482\n","Epoch 125/300\n","96/97 [============================>.] - ETA: 0s - loss: 0.0344 - accuracy: 0.9909\n","Epoch 00125: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0376 - accuracy: 0.9896 - val_loss: 0.6481 - val_accuracy: 0.8653\n","Epoch 126/300\n","93/97 [===========================>..] - ETA: 0s - loss: 0.0428 - accuracy: 0.9852\n","Epoch 00126: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0450 - accuracy: 0.9831 - val_loss: 0.3365 - val_accuracy: 0.9119\n","Epoch 127/300\n","92/97 [===========================>..] - ETA: 0s - loss: 0.0321 - accuracy: 0.9905\n","Epoch 00127: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0308 - accuracy: 0.9909 - val_loss: 0.3821 - val_accuracy: 0.9326\n","Epoch 128/300\n","92/97 [===========================>..] - ETA: 0s - loss: 0.0250 - accuracy: 0.9905\n","Epoch 00128: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0243 - accuracy: 0.9909 - val_loss: 0.4390 - val_accuracy: 0.9119\n","Epoch 129/300\n","93/97 [===========================>..] - ETA: 0s - loss: 0.0391 - accuracy: 0.9892\n","Epoch 00129: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0429 - accuracy: 0.9883 - val_loss: 0.6216 - val_accuracy: 0.8653\n","Epoch 130/300\n","91/97 [===========================>..] - ETA: 0s - loss: 0.0370 - accuracy: 0.9904\n","Epoch 00130: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0362 - accuracy: 0.9909 - val_loss: 0.2858 - val_accuracy: 0.9482\n","Epoch 131/300\n","92/97 [===========================>..] - ETA: 0s - loss: 0.0330 - accuracy: 0.9864\n","Epoch 00131: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0341 - accuracy: 0.9857 - val_loss: 0.3085 - val_accuracy: 0.9275\n","Epoch 132/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.0350 - accuracy: 0.9868\n","Epoch 00132: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0346 - accuracy: 0.9870 - val_loss: 0.2564 - val_accuracy: 0.9378\n","Epoch 133/300\n","96/97 [============================>.] - ETA: 0s - loss: 0.0368 - accuracy: 0.9896\n","Epoch 00133: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0368 - accuracy: 0.9896 - val_loss: 0.2660 - val_accuracy: 0.9430\n","Epoch 134/300\n","90/97 [==========================>...] - ETA: 0s - loss: 0.0465 - accuracy: 0.9861\n","Epoch 00134: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0438 - accuracy: 0.9870 - val_loss: 0.2523 - val_accuracy: 0.9326\n","Epoch 135/300\n","91/97 [===========================>..] - ETA: 0s - loss: 0.0466 - accuracy: 0.9808\n","Epoch 00135: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0446 - accuracy: 0.9818 - val_loss: 0.2887 - val_accuracy: 0.9275\n","Epoch 136/300\n","97/97 [==============================] - ETA: 0s - loss: 0.0274 - accuracy: 0.9883\n","Epoch 00136: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0274 - accuracy: 0.9883 - val_loss: 0.4483 - val_accuracy: 0.9378\n","Epoch 137/300\n","97/97 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 0.9948\n","Epoch 00137: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0210 - accuracy: 0.9948 - val_loss: 0.3655 - val_accuracy: 0.9067\n","Epoch 138/300\n","97/97 [==============================] - ETA: 0s - loss: 0.0261 - accuracy: 0.9948\n","Epoch 00138: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0261 - accuracy: 0.9948 - val_loss: 0.2685 - val_accuracy: 0.9378\n","Epoch 139/300\n","89/97 [==========================>...] - ETA: 0s - loss: 0.0402 - accuracy: 0.9874\n","Epoch 00139: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0456 - accuracy: 0.9870 - val_loss: 0.3628 - val_accuracy: 0.9275\n","Epoch 140/300\n","90/97 [==========================>...] - ETA: 0s - loss: 0.0537 - accuracy: 0.9875\n","Epoch 00140: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0506 - accuracy: 0.9883 - val_loss: 0.3316 - val_accuracy: 0.9326\n","Epoch 141/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.0358 - accuracy: 0.9882\n","Epoch 00141: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0360 - accuracy: 0.9883 - val_loss: 0.3837 - val_accuracy: 0.9119\n","Epoch 142/300\n","93/97 [===========================>..] - ETA: 0s - loss: 0.0507 - accuracy: 0.9852\n","Epoch 00142: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0494 - accuracy: 0.9857 - val_loss: 0.4735 - val_accuracy: 0.9067\n","Epoch 143/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.0407 - accuracy: 0.9882\n","Epoch 00143: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0413 - accuracy: 0.9883 - val_loss: 0.3513 - val_accuracy: 0.9067\n","Epoch 144/300\n","90/97 [==========================>...] - ETA: 0s - loss: 0.0334 - accuracy: 0.9903\n","Epoch 00144: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0321 - accuracy: 0.9909 - val_loss: 0.4041 - val_accuracy: 0.9326\n","Epoch 145/300\n","97/97 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 0.9883\n","Epoch 00145: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0319 - accuracy: 0.9883 - val_loss: 0.3527 - val_accuracy: 0.9326\n","Epoch 146/300\n","90/97 [==========================>...] - ETA: 0s - loss: 0.0205 - accuracy: 0.9958\n","Epoch 00146: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0197 - accuracy: 0.9961 - val_loss: 0.3292 - val_accuracy: 0.9223\n","Epoch 147/300\n","91/97 [===========================>..] - ETA: 0s - loss: 0.0565 - accuracy: 0.9849\n","Epoch 00147: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0553 - accuracy: 0.9844 - val_loss: 0.4911 - val_accuracy: 0.9171\n","Epoch 148/300\n","97/97 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 0.9961\n","Epoch 00148: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0194 - accuracy: 0.9961 - val_loss: 0.4217 - val_accuracy: 0.9326\n","Epoch 149/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.0163 - accuracy: 0.9947\n","Epoch 00149: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0160 - accuracy: 0.9948 - val_loss: 0.3971 - val_accuracy: 0.9171\n","Epoch 150/300\n","93/97 [===========================>..] - ETA: 0s - loss: 0.0205 - accuracy: 0.9933\n","Epoch 00150: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0198 - accuracy: 0.9935 - val_loss: 0.3644 - val_accuracy: 0.9482\n","Epoch 151/300\n","92/97 [===========================>..] - ETA: 0s - loss: 0.0280 - accuracy: 0.9932\n","Epoch 00151: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0269 - accuracy: 0.9935 - val_loss: 0.3099 - val_accuracy: 0.9326\n","Epoch 152/300\n","97/97 [==============================] - ETA: 0s - loss: 0.0536 - accuracy: 0.9883\n","Epoch 00152: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0536 - accuracy: 0.9883 - val_loss: 0.3024 - val_accuracy: 0.9430\n","Epoch 153/300\n","96/97 [============================>.] - ETA: 0s - loss: 0.0139 - accuracy: 0.9935\n","Epoch 00153: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0139 - accuracy: 0.9935 - val_loss: 0.4197 - val_accuracy: 0.9223\n","Epoch 154/300\n","90/97 [==========================>...] - ETA: 0s - loss: 0.0237 - accuracy: 0.9903\n","Epoch 00154: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0263 - accuracy: 0.9896 - val_loss: 0.4418 - val_accuracy: 0.9378\n","Epoch 155/300\n","97/97 [==============================] - ETA: 0s - loss: 0.0438 - accuracy: 0.9935\n","Epoch 00155: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0438 - accuracy: 0.9935 - val_loss: 0.3839 - val_accuracy: 0.9326\n","Epoch 156/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.0308 - accuracy: 0.9920\n","Epoch 00156: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0302 - accuracy: 0.9922 - val_loss: 0.5583 - val_accuracy: 0.9171\n","Epoch 157/300\n","92/97 [===========================>..] - ETA: 0s - loss: 0.0359 - accuracy: 0.9918\n","Epoch 00157: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0345 - accuracy: 0.9922 - val_loss: 0.5155 - val_accuracy: 0.9223\n","Epoch 158/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.0431 - accuracy: 0.9854\n","Epoch 00158: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0423 - accuracy: 0.9857 - val_loss: 0.3559 - val_accuracy: 0.9326\n","Epoch 159/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.0196 - accuracy: 0.9987\n","Epoch 00159: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0192 - accuracy: 0.9987 - val_loss: 0.5311 - val_accuracy: 0.9223\n","Epoch 160/300\n","97/97 [==============================] - ETA: 0s - loss: 0.0376 - accuracy: 0.9909\n","Epoch 00160: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0376 - accuracy: 0.9909 - val_loss: 0.3956 - val_accuracy: 0.9482\n","Epoch 161/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.0109 - accuracy: 0.9961\n","Epoch 00161: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0108 - accuracy: 0.9961 - val_loss: 0.4297 - val_accuracy: 0.9326\n","Epoch 162/300\n","93/97 [===========================>..] - ETA: 0s - loss: 0.0132 - accuracy: 0.9946\n","Epoch 00162: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0139 - accuracy: 0.9948 - val_loss: 0.7822 - val_accuracy: 0.8756\n","Epoch 163/300\n","96/97 [============================>.] - ETA: 0s - loss: 0.0198 - accuracy: 0.9922\n","Epoch 00163: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0197 - accuracy: 0.9922 - val_loss: 0.4149 - val_accuracy: 0.9275\n","Epoch 164/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.0132 - accuracy: 0.9947\n","Epoch 00164: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0130 - accuracy: 0.9948 - val_loss: 0.4878 - val_accuracy: 0.9119\n","Epoch 165/300\n","93/97 [===========================>..] - ETA: 0s - loss: 0.0449 - accuracy: 0.9919\n","Epoch 00165: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0434 - accuracy: 0.9922 - val_loss: 0.4269 - val_accuracy: 0.9378\n","Epoch 166/300\n","93/97 [===========================>..] - ETA: 0s - loss: 0.0224 - accuracy: 0.9933\n","Epoch 00166: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0217 - accuracy: 0.9935 - val_loss: 0.5569 - val_accuracy: 0.9171\n","Epoch 167/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9987\n","Epoch 00167: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.6239 - val_accuracy: 0.9171\n","Epoch 168/300\n","93/97 [===========================>..] - ETA: 0s - loss: 0.0184 - accuracy: 0.9960\n","Epoch 00168: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0179 - accuracy: 0.9961 - val_loss: 0.4683 - val_accuracy: 0.9223\n","Epoch 169/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.0172 - accuracy: 0.9961\n","Epoch 00169: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0170 - accuracy: 0.9961 - val_loss: 0.4859 - val_accuracy: 0.9119\n","Epoch 170/300\n","96/97 [============================>.] - ETA: 0s - loss: 0.0257 - accuracy: 0.9922\n","Epoch 00170: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0257 - accuracy: 0.9922 - val_loss: 0.5714 - val_accuracy: 0.9171\n","Epoch 171/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.0236 - accuracy: 0.9908\n","Epoch 00171: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0233 - accuracy: 0.9909 - val_loss: 0.4873 - val_accuracy: 0.8912\n","Epoch 172/300\n","96/97 [============================>.] - ETA: 0s - loss: 0.0324 - accuracy: 0.9909\n","Epoch 00172: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0324 - accuracy: 0.9909 - val_loss: 0.3962 - val_accuracy: 0.9378\n","Epoch 173/300\n","96/97 [============================>.] - ETA: 0s - loss: 0.0152 - accuracy: 0.9948\n","Epoch 00173: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0152 - accuracy: 0.9948 - val_loss: 0.6521 - val_accuracy: 0.9171\n","Epoch 174/300\n","93/97 [===========================>..] - ETA: 0s - loss: 0.0159 - accuracy: 0.9960\n","Epoch 00174: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0154 - accuracy: 0.9961 - val_loss: 0.5365 - val_accuracy: 0.9067\n","Epoch 175/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.0153 - accuracy: 0.9987\n","Epoch 00175: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0150 - accuracy: 0.9987 - val_loss: 0.4911 - val_accuracy: 0.9119\n","Epoch 176/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.0343 - accuracy: 0.9907\n","Epoch 00176: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0336 - accuracy: 0.9909 - val_loss: 0.6039 - val_accuracy: 0.8964\n","Epoch 177/300\n","90/97 [==========================>...] - ETA: 0s - loss: 0.0162 - accuracy: 0.9944\n","Epoch 00177: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0209 - accuracy: 0.9922 - val_loss: 0.5353 - val_accuracy: 0.9223\n","Epoch 178/300\n","93/97 [===========================>..] - ETA: 0s - loss: 0.0117 - accuracy: 0.9960\n","Epoch 00178: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 0.4673 - val_accuracy: 0.9223\n","Epoch 179/300\n","97/97 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9974\n","Epoch 00179: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0054 - accuracy: 0.9974 - val_loss: 0.5694 - val_accuracy: 0.9223\n","Epoch 180/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.0209 - accuracy: 0.9947\n","Epoch 00180: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0205 - accuracy: 0.9948 - val_loss: 0.6349 - val_accuracy: 0.9223\n","Epoch 181/300\n","92/97 [===========================>..] - ETA: 0s - loss: 0.0166 - accuracy: 0.9932\n","Epoch 00181: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0214 - accuracy: 0.9909 - val_loss: 0.6420 - val_accuracy: 0.9171\n","Epoch 182/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9974\n","Epoch 00182: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0064 - accuracy: 0.9974 - val_loss: 0.6315 - val_accuracy: 0.8964\n","Epoch 183/300\n","93/97 [===========================>..] - ETA: 0s - loss: 0.0337 - accuracy: 0.9960\n","Epoch 00183: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0327 - accuracy: 0.9961 - val_loss: 0.5387 - val_accuracy: 0.9275\n","Epoch 184/300\n","96/97 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9987\n","Epoch 00184: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0063 - accuracy: 0.9987 - val_loss: 0.4947 - val_accuracy: 0.9326\n","Epoch 185/300\n","91/97 [===========================>..] - ETA: 0s - loss: 0.0028 - accuracy: 1.0000\n","Epoch 00185: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.5375 - val_accuracy: 0.9067\n","Epoch 186/300\n","91/97 [===========================>..] - ETA: 0s - loss: 0.0366 - accuracy: 0.9959\n","Epoch 00186: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0346 - accuracy: 0.9961 - val_loss: 0.4418 - val_accuracy: 0.9430\n","Epoch 187/300\n","92/97 [===========================>..] - ETA: 0s - loss: 0.0097 - accuracy: 0.9973\n","Epoch 00187: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0093 - accuracy: 0.9974 - val_loss: 0.6306 - val_accuracy: 0.9171\n","Epoch 188/300\n","97/97 [==============================] - ETA: 0s - loss: 0.0407 - accuracy: 0.9935\n","Epoch 00188: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0407 - accuracy: 0.9935 - val_loss: 0.4402 - val_accuracy: 0.9171\n","Epoch 189/300\n","96/97 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9974\n","Epoch 00189: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0043 - accuracy: 0.9974 - val_loss: 0.4988 - val_accuracy: 0.9378\n","Epoch 190/300\n","92/97 [===========================>..] - ETA: 0s - loss: 0.0130 - accuracy: 0.9959\n","Epoch 00190: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0129 - accuracy: 0.9961 - val_loss: 1.1065 - val_accuracy: 0.9119\n","Epoch 191/300\n","93/97 [===========================>..] - ETA: 0s - loss: 0.0225 - accuracy: 0.9960\n","Epoch 00191: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0218 - accuracy: 0.9961 - val_loss: 0.5805 - val_accuracy: 0.9275\n","Epoch 192/300\n","96/97 [============================>.] - ETA: 0s - loss: 0.0272 - accuracy: 0.9909\n","Epoch 00192: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0272 - accuracy: 0.9909 - val_loss: 0.5474 - val_accuracy: 0.8964\n","Epoch 193/300\n","92/97 [===========================>..] - ETA: 0s - loss: 0.0109 - accuracy: 0.9959\n","Epoch 00193: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0105 - accuracy: 0.9961 - val_loss: 0.5789 - val_accuracy: 0.9223\n","Epoch 194/300\n","97/97 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9948\n","Epoch 00194: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0123 - accuracy: 0.9948 - val_loss: 0.5489 - val_accuracy: 0.9016\n","Epoch 195/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.0119 - accuracy: 0.9961\n","Epoch 00195: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0118 - accuracy: 0.9961 - val_loss: 0.5178 - val_accuracy: 0.9223\n","Epoch 196/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.0124 - accuracy: 0.9974\n","Epoch 00196: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0123 - accuracy: 0.9974 - val_loss: 0.4394 - val_accuracy: 0.9378\n","Epoch 197/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.0196 - accuracy: 0.9947\n","Epoch 00197: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0191 - accuracy: 0.9948 - val_loss: 0.6264 - val_accuracy: 0.9223\n","Epoch 198/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.0133 - accuracy: 0.9974\n","Epoch 00198: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0145 - accuracy: 0.9961 - val_loss: 0.7061 - val_accuracy: 0.9171\n","Epoch 199/300\n","93/97 [===========================>..] - ETA: 0s - loss: 0.0298 - accuracy: 0.9973\n","Epoch 00199: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0290 - accuracy: 0.9974 - val_loss: 0.7612 - val_accuracy: 0.9171\n","Epoch 200/300\n","90/97 [==========================>...] - ETA: 0s - loss: 0.0149 - accuracy: 0.9958\n","Epoch 00200: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0140 - accuracy: 0.9961 - val_loss: 0.5700 - val_accuracy: 0.8964\n","Epoch 201/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9973\n","Epoch 00201: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0058 - accuracy: 0.9974 - val_loss: 0.7112 - val_accuracy: 0.9275\n","Epoch 202/300\n","92/97 [===========================>..] - ETA: 0s - loss: 0.0498 - accuracy: 0.9946\n","Epoch 00202: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0477 - accuracy: 0.9948 - val_loss: 0.9062 - val_accuracy: 0.9171\n","Epoch 203/300\n","91/97 [===========================>..] - ETA: 0s - loss: 0.0096 - accuracy: 0.9959\n","Epoch 00203: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0125 - accuracy: 0.9948 - val_loss: 0.7914 - val_accuracy: 0.9171\n","Epoch 204/300\n","93/97 [===========================>..] - ETA: 0s - loss: 0.0117 - accuracy: 0.9987\n","Epoch 00204: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0113 - accuracy: 0.9987 - val_loss: 0.6998 - val_accuracy: 0.9223\n","Epoch 205/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n","Epoch 00205: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.4319 - val_accuracy: 0.8912\n","Epoch 206/300\n","96/97 [============================>.] - ETA: 0s - loss: 0.0155 - accuracy: 0.9974\n","Epoch 00206: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0155 - accuracy: 0.9974 - val_loss: 0.7320 - val_accuracy: 0.9067\n","Epoch 207/300\n","93/97 [===========================>..] - ETA: 0s - loss: 0.0089 - accuracy: 0.9973\n","Epoch 00207: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0733 - accuracy: 0.9961 - val_loss: 0.5249 - val_accuracy: 0.9275\n","Epoch 208/300\n","95/97 [============================>.] - ETA: 0s - loss: 2.7260e-04 - accuracy: 1.0000\n","Epoch 00208: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 2.6941e-04 - accuracy: 1.0000 - val_loss: 0.8098 - val_accuracy: 0.9223\n","Epoch 209/300\n","97/97 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9935\n","Epoch 00209: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0164 - accuracy: 0.9935 - val_loss: 0.6735 - val_accuracy: 0.9223\n","Epoch 210/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.0086 - accuracy: 0.9973\n","Epoch 00210: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.6429 - val_accuracy: 0.9119\n","Epoch 211/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.0103 - accuracy: 0.9987\n","Epoch 00211: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0101 - accuracy: 0.9987 - val_loss: 0.7652 - val_accuracy: 0.9171\n","Epoch 212/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 0.9960\n","Epoch 00212: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0076 - accuracy: 0.9961 - val_loss: 0.5278 - val_accuracy: 0.9171\n","Epoch 213/300\n","90/97 [==========================>...] - ETA: 0s - loss: 0.0117 - accuracy: 0.9972\n","Epoch 00213: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0110 - accuracy: 0.9974 - val_loss: 0.6444 - val_accuracy: 0.9171\n","Epoch 214/300\n","96/97 [============================>.] - ETA: 0s - loss: 0.0258 - accuracy: 0.9987\n","Epoch 00214: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0257 - accuracy: 0.9987 - val_loss: 0.8406 - val_accuracy: 0.8860\n","Epoch 215/300\n","92/97 [===========================>..] - ETA: 0s - loss: 0.0253 - accuracy: 0.9973\n","Epoch 00215: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0242 - accuracy: 0.9974 - val_loss: 0.6628 - val_accuracy: 0.9016\n","Epoch 216/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.0121 - accuracy: 0.9947\n","Epoch 00216: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0120 - accuracy: 0.9948 - val_loss: 0.8036 - val_accuracy: 0.9171\n","Epoch 217/300\n","91/97 [===========================>..] - ETA: 0s - loss: 0.0244 - accuracy: 0.9931\n","Epoch 00217: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 7ms/step - loss: 0.0231 - accuracy: 0.9935 - val_loss: 0.6433 - val_accuracy: 0.9119\n","Epoch 218/300\n","95/97 [============================>.] - ETA: 0s - loss: 3.4625e-04 - accuracy: 1.0000\n","Epoch 00218: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 3.4220e-04 - accuracy: 1.0000 - val_loss: 0.7891 - val_accuracy: 0.9171\n","Epoch 219/300\n","96/97 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9974\n","Epoch 00219: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0134 - accuracy: 0.9974 - val_loss: 0.5914 - val_accuracy: 0.9119\n","Epoch 220/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.0137 - accuracy: 0.9973\n","Epoch 00220: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0134 - accuracy: 0.9974 - val_loss: 0.6375 - val_accuracy: 0.9275\n","Epoch 221/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9974\n","Epoch 00221: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0049 - accuracy: 0.9974 - val_loss: 0.6870 - val_accuracy: 0.9016\n","Epoch 222/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9987\n","Epoch 00222: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0033 - accuracy: 0.9987 - val_loss: 0.6675 - val_accuracy: 0.9171\n","Epoch 223/300\n","92/97 [===========================>..] - ETA: 0s - loss: 0.0318 - accuracy: 0.9891\n","Epoch 00223: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0305 - accuracy: 0.9896 - val_loss: 0.5727 - val_accuracy: 0.9223\n","Epoch 224/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.9961\n","Epoch 00224: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0091 - accuracy: 0.9961 - val_loss: 0.7510 - val_accuracy: 0.9067\n","Epoch 225/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9974\n","Epoch 00225: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0066 - accuracy: 0.9974 - val_loss: 0.6349 - val_accuracy: 0.9171\n","Epoch 226/300\n","93/97 [===========================>..] - ETA: 0s - loss: 0.0192 - accuracy: 0.9919\n","Epoch 00226: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0189 - accuracy: 0.9922 - val_loss: 1.2931 - val_accuracy: 0.9016\n","Epoch 227/300\n","92/97 [===========================>..] - ETA: 0s - loss: 0.0293 - accuracy: 0.9918\n","Epoch 00227: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0280 - accuracy: 0.9922 - val_loss: 1.0663 - val_accuracy: 0.9119\n","Epoch 228/300\n","91/97 [===========================>..] - ETA: 0s - loss: 0.0222 - accuracy: 0.9959\n","Epoch 00228: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0221 - accuracy: 0.9948 - val_loss: 0.9482 - val_accuracy: 0.8912\n","Epoch 229/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000\n","Epoch 00229: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8175 - val_accuracy: 0.9275\n","Epoch 230/300\n","91/97 [===========================>..] - ETA: 0s - loss: 0.0074 - accuracy: 0.9986\n","Epoch 00230: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0070 - accuracy: 0.9987 - val_loss: 0.6494 - val_accuracy: 0.9223\n","Epoch 231/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.0150 - accuracy: 0.9947\n","Epoch 00231: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0148 - accuracy: 0.9948 - val_loss: 0.6927 - val_accuracy: 0.9326\n","Epoch 232/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9987\n","Epoch 00232: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.7613 - val_accuracy: 0.9171\n","Epoch 233/300\n","96/97 [============================>.] - ETA: 0s - loss: 0.0101 - accuracy: 0.9974\n","Epoch 00233: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 1.1263 - val_accuracy: 0.9171\n","Epoch 234/300\n","92/97 [===========================>..] - ETA: 0s - loss: 0.0283 - accuracy: 0.9959\n","Epoch 00234: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0271 - accuracy: 0.9961 - val_loss: 0.7833 - val_accuracy: 0.9223\n","Epoch 235/300\n","97/97 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 0.9961\n","Epoch 00235: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0155 - accuracy: 0.9961 - val_loss: 0.6981 - val_accuracy: 0.9223\n","Epoch 236/300\n","91/97 [===========================>..] - ETA: 0s - loss: 0.0446 - accuracy: 0.9959\n","Epoch 00236: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0424 - accuracy: 0.9961 - val_loss: 0.7979 - val_accuracy: 0.9067\n","Epoch 237/300\n","93/97 [===========================>..] - ETA: 0s - loss: 0.0094 - accuracy: 0.9946\n","Epoch 00237: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0091 - accuracy: 0.9948 - val_loss: 0.8902 - val_accuracy: 0.9223\n","Epoch 238/300\n","91/97 [===========================>..] - ETA: 0s - loss: 0.0073 - accuracy: 0.9959\n","Epoch 00238: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0069 - accuracy: 0.9961 - val_loss: 0.6050 - val_accuracy: 0.9171\n","Epoch 239/300\n","91/97 [===========================>..] - ETA: 0s - loss: 0.0106 - accuracy: 0.9945\n","Epoch 00239: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0101 - accuracy: 0.9948 - val_loss: 0.8710 - val_accuracy: 0.9275\n","Epoch 240/300\n","93/97 [===========================>..] - ETA: 0s - loss: 0.0130 - accuracy: 0.9960\n","Epoch 00240: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 0.9029 - val_accuracy: 0.9223\n","Epoch 241/300\n","92/97 [===========================>..] - ETA: 0s - loss: 7.2353e-04 - accuracy: 1.0000\n","Epoch 00241: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 7.3275e-04 - accuracy: 1.0000 - val_loss: 2.0968 - val_accuracy: 0.8756\n","Epoch 242/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.0262 - accuracy: 0.9974\n","Epoch 00242: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0259 - accuracy: 0.9974 - val_loss: 0.8690 - val_accuracy: 0.9016\n","Epoch 243/300\n","90/97 [==========================>...] - ETA: 0s - loss: 0.0096 - accuracy: 0.9972    \n","Epoch 00243: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 1.0622 - val_accuracy: 0.9067\n","Epoch 244/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.0217 - accuracy: 0.9947\n","Epoch 00244: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0212 - accuracy: 0.9948 - val_loss: 0.8846 - val_accuracy: 0.9067\n","Epoch 245/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9974\n","Epoch 00245: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0045 - accuracy: 0.9974 - val_loss: 0.8584 - val_accuracy: 0.9067\n","Epoch 246/300\n","97/97 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9961\n","Epoch 00246: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0153 - accuracy: 0.9961 - val_loss: 0.9215 - val_accuracy: 0.9171\n","Epoch 247/300\n","91/97 [===========================>..] - ETA: 0s - loss: 0.0033 - accuracy: 1.0000\n","Epoch 00247: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 9ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2337 - val_accuracy: 0.8808\n","Epoch 248/300\n","92/97 [===========================>..] - ETA: 0s - loss: 0.0318 - accuracy: 0.9946\n","Epoch 00248: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0345 - accuracy: 0.9935 - val_loss: 1.0918 - val_accuracy: 0.9016\n","Epoch 249/300\n","90/97 [==========================>...] - ETA: 0s - loss: 0.0290 - accuracy: 0.9958\n","Epoch 00249: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0271 - accuracy: 0.9961 - val_loss: 0.6125 - val_accuracy: 0.9378\n","Epoch 250/300\n","93/97 [===========================>..] - ETA: 0s - loss: 0.0182 - accuracy: 0.9973\n","Epoch 00250: val_accuracy did not improve from 0.94819\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0176 - accuracy: 0.9974 - val_loss: 0.9399 - val_accuracy: 0.9171\n","Epoch 251/300\n","92/97 [===========================>..] - ETA: 0s - loss: 6.9321e-04 - accuracy: 1.0000\n","Epoch 00251: val_accuracy improved from 0.94819 to 0.95337, saving model to /content/drive/MyDrive/Colab_Dataset/Brain Cancer/v3/PreConv.h5\n","97/97 [==============================] - 2s 18ms/step - loss: 6.6347e-04 - accuracy: 1.0000 - val_loss: 0.5516 - val_accuracy: 0.9534\n","Epoch 252/300\n","97/97 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 0.9961\n","Epoch 00252: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 9ms/step - loss: 0.0187 - accuracy: 0.9961 - val_loss: 0.6169 - val_accuracy: 0.9378\n","Epoch 253/300\n","93/97 [===========================>..] - ETA: 0s - loss: 0.0118 - accuracy: 0.9946\n","Epoch 00253: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0114 - accuracy: 0.9948 - val_loss: 0.6975 - val_accuracy: 0.9223\n","Epoch 254/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.9947\n","Epoch 00254: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0173 - accuracy: 0.9948 - val_loss: 0.7147 - val_accuracy: 0.9171\n","Epoch 255/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.0139 - accuracy: 0.9973\n","Epoch 00255: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0136 - accuracy: 0.9974 - val_loss: 0.6377 - val_accuracy: 0.8912\n","Epoch 256/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9974\n","Epoch 00256: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0070 - accuracy: 0.9974 - val_loss: 0.7724 - val_accuracy: 0.9223\n","Epoch 257/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.0140 - accuracy: 0.9973\n","Epoch 00257: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0137 - accuracy: 0.9974 - val_loss: 0.8442 - val_accuracy: 0.9223\n","Epoch 258/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.0492 - accuracy: 0.9934\n","Epoch 00258: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0481 - accuracy: 0.9935 - val_loss: 0.7148 - val_accuracy: 0.9275\n","Epoch 259/300\n","89/97 [==========================>...] - ETA: 0s - loss: 0.0076 - accuracy: 0.9972\n","Epoch 00259: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0070 - accuracy: 0.9974 - val_loss: 0.6937 - val_accuracy: 0.9171\n","Epoch 260/300\n","96/97 [============================>.] - ETA: 0s - loss: 0.0320 - accuracy: 0.9922\n","Epoch 00260: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0319 - accuracy: 0.9922 - val_loss: 0.7740 - val_accuracy: 0.9171\n","Epoch 261/300\n","96/97 [============================>.] - ETA: 0s - loss: 0.0275 - accuracy: 0.9948\n","Epoch 00261: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0275 - accuracy: 0.9948 - val_loss: 0.7160 - val_accuracy: 0.9223\n","Epoch 262/300\n","92/97 [===========================>..] - ETA: 0s - loss: 0.0127 - accuracy: 0.9973\n","Epoch 00262: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0121 - accuracy: 0.9974 - val_loss: 0.7464 - val_accuracy: 0.9171\n","Epoch 263/300\n","96/97 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9987\n","Epoch 00263: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0027 - accuracy: 0.9987 - val_loss: 1.0188 - val_accuracy: 0.9223\n","Epoch 264/300\n","91/97 [===========================>..] - ETA: 0s - loss: 0.0284 - accuracy: 0.9945\n","Epoch 00264: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0272 - accuracy: 0.9948 - val_loss: 1.0653 - val_accuracy: 0.9171\n","Epoch 265/300\n","92/97 [===========================>..] - ETA: 0s - loss: 0.0332 - accuracy: 0.9918\n","Epoch 00265: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0317 - accuracy: 0.9922 - val_loss: 0.7198 - val_accuracy: 0.9119\n","Epoch 266/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.0144 - accuracy: 0.9947\n","Epoch 00266: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0142 - accuracy: 0.9948 - val_loss: 1.0937 - val_accuracy: 0.9016\n","Epoch 267/300\n","96/97 [============================>.] - ETA: 0s - loss: 0.0107 - accuracy: 0.9961\n","Epoch 00267: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0107 - accuracy: 0.9961 - val_loss: 0.7111 - val_accuracy: 0.9119\n","Epoch 268/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.0131 - accuracy: 0.9987\n","Epoch 00268: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0129 - accuracy: 0.9987 - val_loss: 0.8114 - val_accuracy: 0.9223\n","Epoch 269/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000    \n","Epoch 00269: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.0009 - val_accuracy: 0.9171\n","Epoch 270/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.0339 - accuracy: 0.9947\n","Epoch 00270: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0331 - accuracy: 0.9948 - val_loss: 1.0703 - val_accuracy: 0.8860\n","Epoch 271/300\n","90/97 [==========================>...] - ETA: 0s - loss: 0.0159 - accuracy: 0.9972\n","Epoch 00271: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0162 - accuracy: 0.9961 - val_loss: 0.9242 - val_accuracy: 0.9119\n","Epoch 272/300\n","97/97 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 0.9974\n","Epoch 00272: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.8032 - val_accuracy: 0.9171\n","Epoch 273/300\n","96/97 [============================>.] - ETA: 0s - loss: 0.0266 - accuracy: 0.9948\n","Epoch 00273: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0266 - accuracy: 0.9948 - val_loss: 0.9716 - val_accuracy: 0.8756\n","Epoch 274/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n","Epoch 00274: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9748 - val_accuracy: 0.9171\n","Epoch 275/300\n","96/97 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9974\n","Epoch 00275: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0067 - accuracy: 0.9974 - val_loss: 1.2864 - val_accuracy: 0.9067\n","Epoch 276/300\n","90/97 [==========================>...] - ETA: 0s - loss: 0.0341 - accuracy: 0.9972\n","Epoch 00276: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0319 - accuracy: 0.9974 - val_loss: 0.9063 - val_accuracy: 0.9067\n","Epoch 277/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.0245 - accuracy: 0.9947\n","Epoch 00277: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0240 - accuracy: 0.9948 - val_loss: 1.3766 - val_accuracy: 0.9016\n","Epoch 278/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9987\n","Epoch 00278: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0019 - accuracy: 0.9987 - val_loss: 0.7928 - val_accuracy: 0.9171\n","Epoch 279/300\n","97/97 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9961\n","Epoch 00279: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0107 - accuracy: 0.9961 - val_loss: 0.6722 - val_accuracy: 0.9223\n","Epoch 280/300\n","90/97 [==========================>...] - ETA: 0s - loss: 3.2874e-04 - accuracy: 1.0000\n","Epoch 00280: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 3.1522e-04 - accuracy: 1.0000 - val_loss: 1.0751 - val_accuracy: 0.9326\n","Epoch 281/300\n","97/97 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 0.9974\n","Epoch 00281: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0235 - accuracy: 0.9974 - val_loss: 0.9584 - val_accuracy: 0.9171\n","Epoch 282/300\n","97/97 [==============================] - ETA: 0s - loss: 0.0217 - accuracy: 0.9961\n","Epoch 00282: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0217 - accuracy: 0.9961 - val_loss: 0.5858 - val_accuracy: 0.9171\n","Epoch 283/300\n","96/97 [============================>.] - ETA: 0s - loss: 0.0119 - accuracy: 0.9961\n","Epoch 00283: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 0.9171 - val_accuracy: 0.9223\n","Epoch 284/300\n","97/97 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 0.9987\n","Epoch 00284: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0170 - accuracy: 0.9987 - val_loss: 1.2981 - val_accuracy: 0.9119\n","Epoch 285/300\n","97/97 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 0.9961\n","Epoch 00285: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0137 - accuracy: 0.9961 - val_loss: 1.1193 - val_accuracy: 0.9171\n","Epoch 286/300\n","96/97 [============================>.] - ETA: 0s - loss: 0.0410 - accuracy: 0.9948\n","Epoch 00286: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0410 - accuracy: 0.9948 - val_loss: 0.6664 - val_accuracy: 0.9067\n","Epoch 287/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.0102 - accuracy: 0.9974\n","Epoch 00287: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 9ms/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 0.8556 - val_accuracy: 0.9171\n","Epoch 288/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.0147 - accuracy: 0.9960\n","Epoch 00288: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0144 - accuracy: 0.9961 - val_loss: 0.7820 - val_accuracy: 0.9275\n","Epoch 289/300\n","94/97 [============================>.] - ETA: 0s - loss: 0.0185 - accuracy: 0.9973\n","Epoch 00289: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0181 - accuracy: 0.9974 - val_loss: 0.6622 - val_accuracy: 0.9275\n","Epoch 290/300\n","97/97 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9987\n","Epoch 00290: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 1.3622 - val_accuracy: 0.9223\n","Epoch 291/300\n","93/97 [===========================>..] - ETA: 0s - loss: 0.0308 - accuracy: 0.9919\n","Epoch 00291: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0298 - accuracy: 0.9922 - val_loss: 0.9394 - val_accuracy: 0.9119\n","Epoch 292/300\n","97/97 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.9974\n","Epoch 00292: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0121 - accuracy: 0.9974 - val_loss: 1.5545 - val_accuracy: 0.8912\n","Epoch 293/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.0273 - accuracy: 0.9947\n","Epoch 00293: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0270 - accuracy: 0.9948 - val_loss: 0.6117 - val_accuracy: 0.9275\n","Epoch 294/300\n","93/97 [===========================>..] - ETA: 0s - loss: 0.0232 - accuracy: 0.9960\n","Epoch 00294: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0225 - accuracy: 0.9961 - val_loss: 0.9251 - val_accuracy: 0.9223\n","Epoch 295/300\n","92/97 [===========================>..] - ETA: 0s - loss: 0.0083 - accuracy: 0.9986\n","Epoch 00295: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 0.7708 - val_accuracy: 0.9171\n","Epoch 296/300\n","92/97 [===========================>..] - ETA: 0s - loss: 4.2918e-04 - accuracy: 1.0000\n","Epoch 00296: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 4.1148e-04 - accuracy: 1.0000 - val_loss: 0.8742 - val_accuracy: 0.9171\n","Epoch 297/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.0199 - accuracy: 0.9934\n","Epoch 00297: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0197 - accuracy: 0.9935 - val_loss: 0.8167 - val_accuracy: 0.9067\n","Epoch 298/300\n","96/97 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9987\n","Epoch 00298: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 1.2190 - val_accuracy: 0.9119\n","Epoch 299/300\n","95/97 [============================>.] - ETA: 0s - loss: 0.0140 - accuracy: 0.9987\n","Epoch 00299: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0138 - accuracy: 0.9987 - val_loss: 1.0136 - val_accuracy: 0.9119\n","Epoch 300/300\n","92/97 [===========================>..] - ETA: 0s - loss: 0.0190 - accuracy: 0.9973\n","Epoch 00300: val_accuracy did not improve from 0.95337\n","97/97 [==============================] - 1s 8ms/step - loss: 0.0189 - accuracy: 0.9974 - val_loss: 1.0014 - val_accuracy: 0.9016\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":541},"id":"Ay46q3K2hL30","executionInfo":{"status":"ok","timestamp":1607892102518,"user_tz":-330,"elapsed":241309,"user":{"displayName":"Arindam Majee","photoUrl":"","userId":"08922294135040060764"}},"outputId":"ed4fa6c4-f088-477f-d070-4af69390e5cf"},"source":["#VISUALISING THE MODEL\n","acc = history.history['accuracy']\n","epochs = range(1, len(acc) + 1)\n","val_acc = history.history['val_accuracy']\n","plt.plot(epochs, acc, color='red', label='Training Accuracy')\n","plt.plot(epochs, val_acc, color='blue', label='Validation Accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.show()\n","\n","loss = history.history['loss']\n","epochs = range(1, len(loss) + 1)\n","val_loss = history.history['val_loss']\n","plt.plot(epochs, loss, color='red', label='Training Loss')\n","plt.plot(epochs, val_loss, color='blue', label='Validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()"],"execution_count":7,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7thd3igEyHlb","executionInfo":{"status":"ok","timestamp":1607892190717,"user_tz":-330,"elapsed":4769,"user":{"displayName":"Arindam Majee","photoUrl":"","userId":"08922294135040060764"}},"outputId":"f5263b14-2ef1-4dd1-f0ef-166e5fe717b4"},"source":["classifier = tf.keras.models.load_model('/content/drive/MyDrive/Colab_Dataset/Brain Cancer/v3/PreConv.h5')\n","evaluation = classifier.evaluate(X_test, Y_test)\n","print('Loss : ', evaluation[0])\n","print('Accuracy : ', evaluation[1])"],"execution_count":9,"outputs":[{"output_type":"stream","text":["7/7 [==============================] - 0s 8ms/step - loss: 0.5516 - accuracy: 0.9534\n","Loss :  0.5516236424446106\n","Accuracy :  0.9533678889274597\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z2tMsjy-177-","executionInfo":{"status":"ok","timestamp":1607892432264,"user_tz":-330,"elapsed":3957,"user":{"displayName":"Arindam Majee","photoUrl":"","userId":"08922294135040060764"}},"outputId":"117b201a-df07-4ac4-f085-850028789494"},"source":["# Convert Keras model to TF Lite format.\n","model = keras.models.load_model('/content/drive/MyDrive/Colab_Dataset/Brain Cancer/v3/PreConv.h5')\n","converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","tflite_float_model = converter.convert()\n","\n","# Show model size in MBs.\n","float_model_size = len(tflite_float_model) / (1024*1024)\n","\n","#Save the TFLite Model\n","with open(\"/content/drive/MyDrive/Colab_Dataset/Brain Cancer/v3/PreConv_TFLite.tflite\", \"wb\") as f:\n","  f.write(tflite_float_model)\n","print(f\"\\n\\nWrote TFLite model of {len(tflite_float_model)/(1024*1024)} mb.\")"],"execution_count":10,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n","INFO:tensorflow:Assets written to: /tmp/tmpgpfx9fu8/assets\n","\n","\n","Wrote TFLite model of 0.8954658508300781 mb.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W95Ja2BV2NjG","executionInfo":{"status":"ok","timestamp":1607892527307,"user_tz":-330,"elapsed":3498,"user":{"displayName":"Arindam Majee","photoUrl":"","userId":"08922294135040060764"}},"outputId":"7b801f40-d1cc-4dcc-bf48-d2c15846561d"},"source":["# Re-convert the model to TF Lite using quantization.\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","tflite_quantized_model = converter.convert()\n","\n","# Show model size in KBs.\n","quantized_model_size = len(tflite_quantized_model) / (1024*1024)\n","print('Quantized model size = %f mb,' % quantized_model_size)\n","print('which is about %d%% of the float model size.'\\\n","      % (quantized_model_size * 100 / float_model_size))\n","\n","#Save this Quantized TFLite Model\n","with open(\"/content/drive/MyDrive/Colab_Dataset/Brain Cancer/v3/PreConv_Quantized.tflite\", \"wb\") as f:\n","  f.write(tflite_quantized_model)\n","print(\"Wrote %sTFLite model of %f mb.\" %\n","      (\"optimized \" if tflite_quantized_model else \"\", len(tflite_quantized_model)/(1024*1024)))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Assets written to: /tmp/tmpmldb2rth/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: /tmp/tmpmldb2rth/assets\n"],"name":"stderr"},{"output_type":"stream","text":["Quantized model size = 0.232147 mb,\n","which is about 25% of the float model size.\n","Wrote optimized TFLite model of 0.232147 mb.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6km31dvH2Nq-","executionInfo":{"status":"ok","timestamp":1607892534431,"user_tz":-330,"elapsed":4175,"user":{"displayName":"Arindam Majee","photoUrl":"","userId":"08922294135040060764"}},"outputId":"63a11347-86a4-41f6-d19d-071052a5d341"},"source":["from tensorflow import keras\n","\n","#Read the model in\n","tflite_model = '/content/drive/MyDrive/Colab_Dataset/Brain Cancer/v3/PreConv_TFLite.tflite'\n","tflite_model_quantized = '/content/drive/MyDrive/Colab_Dataset/Brain Cancer/v3/PreConv_Quantized.tflite'\n","\n","# Initialize TFLite interpreter using the model.\n","# Load TFLite model and allocate tensors.\n","\n","#normal\n","interpreter = tf.lite.Interpreter(model_path=tflite_model)\n","interpreter.allocate_tensors()\n","#quantized\n","interpreter_q = tf.lite.Interpreter(model_path=tflite_model_quantized)\n","interpreter_q.allocate_tensors()\n","\n","# Get input and output tensors.\n","input_details = interpreter.get_input_details()\n","output_details = interpreter.get_output_details()\n","\n","input_details_q = interpreter_q.get_input_details()\n","output_details_q = interpreter_q.get_output_details()\n","n = 0  #count for accuracy\n","q = 0\n","normal = []\n","quantized = []\n","# Test model on input data.\n","for i in range(1, len(X_test)):\n","  test_image = np.expand_dims(X_test[i], axis=0).astype(np.float32)\n","  interpreter.set_tensor(input_details[0]['index'], test_image)\n","  interpreter_q.set_tensor(input_details_q[0]['index'], test_image)\n","  interpreter.invoke()\n","  interpreter_q.invoke()\n","\n","  # The function `get_tensor()` returns a copy of the tensor data.\n","  # Use `tensor()` in order to get a pointer to the tensor.\n","  output_data = interpreter.get_tensor(output_details[0]['index'])\n","  output_data_q = interpreter_q.get_tensor(output_details_q[0]['index'])\n","\n","  if np.argmax(output_data)==np.argmax(Y_test[i]):\n","    n+=1\n","  else:\n","    normal.append(i)\n","\n","  if np.argmax(output_data_q)==np.argmax(Y_test[i]):\n","    q+=1\n","  else:\n","    quantized.append(i)\n","print('\\n\\nAccuracy of normal model= ', n/len(X_test))\n","print('\\n\\nAccuracy of quantized model= ', q/len(X_test))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["\n","\n","Accuracy of normal model=  0.9481865284974094\n","\n","\n","Accuracy of quantized model=  0.9430051813471503\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sWJKhVDr2Ntx","executionInfo":{"status":"ok","timestamp":1607892553459,"user_tz":-330,"elapsed":1621,"user":{"displayName":"Arindam Majee","photoUrl":"","userId":"08922294135040060764"}},"outputId":"3763b866-4fc4-49b3-da6c-ce16aab36cf9"},"source":["print('Wrongly classified images of normal model :', normal)\n","print('Wrongly classified images of quantized model :', quantized)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Wrongly classified images of normal model : [27, 65, 71, 87, 116, 128, 135, 137, 171]\n","Wrongly classified images of quantized model : [27, 65, 71, 87, 116, 122, 128, 135, 137, 171]\n"],"name":"stdout"}]}]}