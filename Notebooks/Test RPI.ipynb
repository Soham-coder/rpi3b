{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Test RPI.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1sDsX8Lmu7AIdAOK8aYyH3wFpiOkEiZl0","authorship_tag":"ABX9TyMJZFZiVNh4XQWoreQLMzfS"},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"4eUxUFyX44-w"},"source":["**Pre-conv**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"83QFK3e-44Eu","executionInfo":{"status":"ok","timestamp":1610287773405,"user_tz":-330,"elapsed":19449,"user":{"displayName":"Arindam Majee","photoUrl":"","userId":"08922294135040060764"}},"outputId":"350736cc-39cc-4687-90c1-e45c8cff3720"},"source":["#PUt the paths here.\n","test_data = '/content/drive/MyDrive/Brain Cancer/Test Data for RPi'\n","original_model = '/content/drive/MyDrive/Brain Cancer/v3/PreConv.h5'\n","tflite_model = '/content/drive/MyDrive/Brain Cancer/v3/PreConv_TFLite.tflite'\n","tflite_model_quantized = '/content/drive/MyDrive/Brain Cancer/v3/PreConv_Quantized.tflite'\n","\n","\n","#Imort the packages\n","import time\n","import tensorflow as tf\n","from tensorflow import keras\n","print(tf.__version__)\n","print(tf.keras.__version__)    \n","#Output must be \n","#2.3.0\n","#2.4.0\n","import numpy as np\n","import cv2\n","import  os\n","from sklearn.preprocessing import OneHotEncoder\n","import pywt\n","print('All packages are imported')\n","\n","\n","def read_image(im_path):\n","  img = cv2.imread(im_path,0)\n","  img = cv2.resize(img,(240,240))\n","  return img\n","  \n","  \n","time0 = time.time()\n","x_test, y_test = [], []\n","list_folder=os.listdir(path = test_data)\n","for i in list_folder:\n","  new_path=os.path.join(test_data,i) \n","  pic_list=os.listdir(new_path)                                              \n","  for img in pic_list:  \n","    im_path = os.path.join(new_path,img)\n","    image = read_image(im_path)\n","    if i == 'flair':\n","      label = 0\n","    elif i == 't1':\n","      label = 1\n","    elif i == 't1ce':\n","      label = 2\n","    elif i == 't2':\n","      label = 3\n","    x_test.append(image) \n","    y_test.append(label) \n","\n","\n","X_test = np.array(x_test).reshape(-1,240,240,1)\n","X_test = X_test/255\n","y_test = np.array(y_test).reshape(-1,1)\n","encoder = OneHotEncoder()\n","y_test = encoder.fit_transform(y_test)\n","Y_test = y_test.toarray()\n","time1 = time.time()\n","print(\"Test images reading is done\")\n","print(\"Number of Test images\",X_test.shape[0])\n","print(\"Time for reading and Preprocessing\", time1 - time0)\n","print(\"Average time for reading and pre-processing\", (time1-time0)/X_test.shape[0])\n","\n","\n","#Read the models\n","# Initialize TFLite interpreter using the model.\n","# Load TFLite model and allocate tensors.\n","time2 = time.time()\n","#original\n","original = tf.keras.models.load_model(original_model)\n","#TFLite\n","interpreter = tf.lite.Interpreter(model_path=tflite_model)\n","interpreter.allocate_tensors()\n","#quantized\n","interpreter_q = tf.lite.Interpreter(model_path=tflite_model_quantized)\n","interpreter_q.allocate_tensors()\n","time3 = time.time()\n","print(\"\\nTime for Loading all models\", time3 - time2)\n","\n","\n","# Get input and output tensors.\n","#TFLite\n","input_details = interpreter.get_input_details()\n","output_details = interpreter.get_output_details()\n","#Quantized\n","input_details_q = interpreter_q.get_input_details()\n","output_details_q = interpreter_q.get_output_details()\n","\n","#Evaluation\n","#original\n","time4 = time.time()\n","evaluation = original.evaluate(X_test, Y_test)\n","time5 = time.time()\n","print('\\Accuracy of Original : ', evaluation[1])\n","print(\"Total time to predict all\", time5 -time4)\n","print(\"Average time to predict: \", (time5 -time4)/len(X_test))\n","\n","time6 = time.time()\n","n = 0  #count for accuracy\n","normal = []\n","# Test model on input data.\n","for i in range(1, len(X_test)):\n","  test_image = np.expand_dims(X_test[i], axis=0).astype(np.float32)\n","  interpreter.set_tensor(input_details[0]['index'], test_image)\n","  interpreter.invoke()\n","\n","  # The function `get_tensor()` returns a copy of the tensor data.\n","  # Use `tensor()` in order to get a pointer to the tensor.\n","  output_data = interpreter.get_tensor(output_details[0]['index'])\n","  \n","  if np.argmax(output_data)==np.argmax(Y_test[i]):\n","    n+=1\n","  else:\n","    normal.append(i)\n","\n","time7 = time.time()\n","print('\\n\\nAccuracy of TFLite model= ', n/len(X_test))\n","print(\"Time to predict all \" , len(X_test), \" images is: \", time7-time6)\n","print(\"Average time to predict a image is: \", (time7-time6)/len(X_test))\n","    \n","time8 = time.time()\n","q = 0\n","quantized = []\n","# Test model on input data.\n","for i in range(1, len(X_test)):\n","  test_image = np.expand_dims(X_test[i], axis=0).astype(np.float32)\n","  interpreter_q.set_tensor(input_details_q[0]['index'], test_image)\n","  interpreter_q.invoke()\n","\n","  # The function `get_tensor()` returns a copy of the tensor data.\n","  # Use `tensor()` in order to get a pointer to the tensor.\n","  output_data_q = interpreter_q.get_tensor(output_details_q[0]['index'])\n","\n","\n","  if np.argmax(output_data_q)==np.argmax(Y_test[i]):\n","    q+=1\n","  else:\n","    quantized.append(i)\n","\n","time9 = time.time()\n","print('\\n\\nAccuracy of quantized model= ', q/len(X_test))\n","print(\"Time to predict all \", len(X_test), \" images is: \", time9-time8)\n","print(\"Average time to predict a image is: \", (time9-time8)/len(X_test))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["2.4.0\n","2.4.0\n","All packages are imported\n","Test images reading is done\n","Number of Test images 193\n","Time for reading and Preprocessing 0.6117165088653564\n","Average time for reading and pre-processing 0.00316951558997594\n","\n","Time for Loading all models 0.1615772247314453\n","7/7 [==============================] - 0s 8ms/step - loss: 0.5516 - accuracy: 0.9534\n","\\Accuracy of Original :  0.9533678889274597\n","Total time to predict all 0.249525785446167\n","Average time to predict:  0.0012928797173376529\n","\n","\n","Accuracy of TFLite model=  0.9481865284974094\n","Time to predict all  193  images is:  1.429603099822998\n","Average time to predict a image is:  0.00740726994726942\n","\n","\n","Accuracy of quantized model=  0.9430051813471503\n","Time to predict all  193  images is:  11.35194206237793\n","Average time to predict a image is:  0.05881835265480793\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wYwOJ4bqNjP9"},"source":["**DWT + Pre-Conv**"]},{"cell_type":"code","metadata":{"id":"a-rrF-74Nh8F","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610287778472,"user_tz":-330,"elapsed":24487,"user":{"displayName":"Arindam Majee","photoUrl":"","userId":"08922294135040060764"}},"outputId":"a21801af-e6f7-47ad-8ee8-d7b3dffd46ec"},"source":["#PUt the paths here.\n","test_data = '/content/drive/MyDrive/Brain Cancer/Test Data for RPi'\n","original_model = '/content/drive/MyDrive/Brain Cancer/v3/DWT_Com_+_Pre-Conv.h5'\n","tflite_model = '/content/drive/MyDrive/Brain Cancer/v3/DWT_Com_+_Pre-Conv_TFLite.tflite'\n","tflite_model_quantized = '/content/drive/MyDrive/Brain Cancer/v3/DWT_Com_+_Pre-Conv_Quantized.tflite'\n","\n","\n","#Imort the packages\n","import time\n","import tensorflow as tf\n","from tensorflow import keras\n","print(tf.__version__)\n","print(tf.keras.__version__)    \n","#Output must be \n","#2.3.0\n","#2.4.0\n","import numpy as np\n","import cv2\n","import  os\n","from sklearn.preprocessing import OneHotEncoder\n","import pywt\n","print('All packages are imported')\n","\n","\n","x_test, y_test = [], []\n","list_folder=os.listdir(path = test_data)\n","for i in list_folder:\n","  new_path=os.path.join(test_data,i) \n","  pic_list=os.listdir(new_path)                                              \n","  for img in pic_list:  \n","    im_path = os.path.join(new_path,img)\n","    image = read_image(im_path)\n","    cA, _ = pywt.dwt2(image,'db2')    #Performing DWT operation\n","    if i == 'flair':\n","      label = 0\n","    elif i == 't1':\n","      label = 1\n","    elif i == 't1ce':\n","      label = 2\n","    elif i == 't2':\n","      label = 3\n","    x_test.append(cA) \n","    y_test.append(label) \n","\n","\n","X_test = np.array(x_test).reshape(-1,121,121,1)\n","X_test = X_test/255\n","y_test = np.array(y_test).reshape(-1,1)\n","encoder = OneHotEncoder()\n","y_test = encoder.fit_transform(y_test)\n","Y_test = y_test.toarray()\n","time1 = time.time()\n","print(\"Test images reading is done\")\n","print(\"Number of Test images\",X_test.shape[0])\n","print(\"Time for reading and Preprocessing\", time1 - time0)\n","print(\"Average time for reading and pre-processing\", (time1-time0)/X_test.shape[0])\n","\n","\n","#Read the models\n","# Initialize TFLite interpreter using the model.\n","# Load TFLite model and allocate tensors.\n","time2 = time.time()\n","#original\n","original = tf.keras.models.load_model(original_model)\n","#TFLite\n","interpreter = tf.lite.Interpreter(model_path=tflite_model)\n","interpreter.allocate_tensors()\n","#quantized\n","interpreter_q = tf.lite.Interpreter(model_path=tflite_model_quantized)\n","interpreter_q.allocate_tensors()\n","time3 = time.time()\n","print(\"\\nTime for Loading all models\", time3 - time2)\n","\n","\n","# Get input and output tensors.\n","#TFLite\n","input_details = interpreter.get_input_details()\n","output_details = interpreter.get_output_details()\n","#Quantized\n","input_details_q = interpreter_q.get_input_details()\n","output_details_q = interpreter_q.get_output_details()\n","\n","#Evaluation\n","#original\n","time4 = time.time()\n","evaluation = original.evaluate(X_test, Y_test)\n","time5 = time.time()\n","print('\\Accuracy of Original : ', evaluation[1])\n","print(\"Total time to predict all\", time5 -time4)\n","print(\"Average time to predict: \", (time5 -time4)/len(X_test))\n","\n","time6 = time.time()\n","n = 0  #count for accuracy\n","normal = []\n","# Test model on input data.\n","for i in range(1, len(X_test)):\n","  test_image = np.expand_dims(X_test[i], axis=0).astype(np.float32)\n","  interpreter.set_tensor(input_details[0]['index'], test_image)\n","  interpreter.invoke()\n","\n","  # The function `get_tensor()` returns a copy of the tensor data.\n","  # Use `tensor()` in order to get a pointer to the tensor.\n","  output_data = interpreter.get_tensor(output_details[0]['index'])\n","  \n","  if np.argmax(output_data)==np.argmax(Y_test[i]):\n","    n+=1\n","  else:\n","    normal.append(i)\n","\n","time7 = time.time()\n","print('\\n\\nAccuracy of TFLite model= ', n/len(X_test))\n","print(\"Time to predict all \" , len(X_test), \" images is: \", time7-time6)\n","print(\"Average time to predict a image is: \", (time7-time6)/len(X_test))\n","    \n","time8 = time.time()\n","q = 0\n","quantized = []\n","# Test model on input data.\n","for i in range(1, len(X_test)):\n","  test_image = np.expand_dims(X_test[i], axis=0).astype(np.float32)\n","  interpreter_q.set_tensor(input_details_q[0]['index'], test_image)\n","  interpreter_q.invoke()\n","\n","  # The function `get_tensor()` returns a copy of the tensor data.\n","  # Use `tensor()` in order to get a pointer to the tensor.\n","  output_data_q = interpreter_q.get_tensor(output_details_q[0]['index'])\n","\n","\n","  if np.argmax(output_data_q)==np.argmax(Y_test[i]):\n","    q+=1\n","  else:\n","    quantized.append(i)\n","\n","time9 = time.time()\n","print('\\n\\nAccuracy of quantized model= ', q/len(X_test))\n","print(\"Time to predict all \", len(X_test), \" images is: \", time9-time8)\n","print(\"Average time to predict a image is: \", (time9-time8)/len(X_test))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["2.4.0\n","2.4.0\n","All packages are imported\n","Test images reading is done\n","Number of Test images 193\n","Time for reading and Preprocessing 14.739645719528198\n","Average time for reading and pre-processing 0.07637122134470568\n","\n","Time for Loading all models 0.18595075607299805\n","7/7 [==============================] - 0s 5ms/step - loss: 0.3583 - accuracy: 0.9223\n","\\Accuracy of Original :  0.9222797751426697\n","Total time to predict all 0.2420654296875\n","Average time to predict:  0.0012542250242875647\n","\n","\n","Accuracy of TFLite model=  0.917098445595855\n","Time to predict all  193  images is:  0.46111631393432617\n","Average time to predict a image is:  0.0023892036991415865\n","\n","\n","Accuracy of quantized model=  0.917098445595855\n","Time to predict all  193  images is:  2.989502429962158\n","Average time to predict a image is:  0.015489649896176986\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gVb3JmIJ7X2g"},"source":["**Pre-Conv + Spark**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K51fSqkv7gEN","executionInfo":{"status":"ok","timestamp":1610287782864,"user_tz":-330,"elapsed":28866,"user":{"displayName":"Arindam Majee","photoUrl":"","userId":"08922294135040060764"}},"outputId":"a7ceafc3-a125-4874-b29b-b67cc871fc92"},"source":["#PUt the paths here.\n","test_data = '/content/drive/MyDrive/Brain Cancer/Test Data for RPi'\n","original_model = '/content/drive/MyDrive/Brain Cancer/v3/PreConv_Spark.h5'\n","tflite_model = '/content/drive/MyDrive/Brain Cancer/v3/PreConv_Spark_TFLite.tflite'\n","tflite_model_quantized = '/content/drive/MyDrive/Brain Cancer/v3/PreConv_Spark_Quantized.tflite'\n","\n","\n","#Imort the packages\n","import time\n","import tensorflow as tf\n","from tensorflow import keras\n","print(tf.__version__)\n","print(tf.keras.__version__)    \n","#Output must be \n","#2.3.0\n","#2.4.0\n","import numpy as np\n","import cv2\n","import  os\n","from sklearn.preprocessing import OneHotEncoder\n","print('All packages are imported')\n","\n","\n","def read_image(im_path):\n","  img = cv2.imread(im_path,0)\n","  img = cv2.resize(img,(240,240))\n","  return img\n","  \n","  \n","time0 = time.time()\n","x_test, y_test = [], []\n","list_folder=os.listdir(path = test_data)\n","for i in list_folder:\n","  new_path=os.path.join(test_data,i) \n","  pic_list=os.listdir(new_path)                                              \n","  for img in pic_list:  \n","    im_path = os.path.join(new_path,img)\n","    image = read_image(im_path)\n","    if i == 'flair':\n","      label = 0\n","    elif i == 't1':\n","      label = 1\n","    elif i == 't1ce':\n","      label = 2\n","    elif i == 't2':\n","      label = 3\n","    x_test.append(image) \n","    y_test.append(label) \n","\n","\n","X_test = np.array(x_test).reshape(-1,240,240,1)\n","X_test = X_test/255\n","y_test = np.array(y_test).reshape(-1,1)\n","encoder = OneHotEncoder()\n","y_test = encoder.fit_transform(y_test)\n","Y_test = y_test.toarray()\n","time1 = time.time()\n","print(\"Test images reading is done\")\n","print(\"Number of Test images\",X_test.shape[0])\n","print(\"Time for reading and Preprocessing\", time1 - time0)\n","print(\"Average time for reading and pre-processing\", (time1-time0)/X_test.shape[0])\n","\n","\n","#Read the models\n","# Initialize TFLite interpreter using the model.\n","# Load TFLite model and allocate tensors.\n","time2 = time.time()\n","#original\n","original = tf.keras.models.load_model(original_model)\n","#TFLite\n","interpreter = tf.lite.Interpreter(model_path=tflite_model)\n","interpreter.allocate_tensors()\n","#quantized\n","interpreter_q = tf.lite.Interpreter(model_path=tflite_model_quantized)\n","interpreter_q.allocate_tensors()\n","time3 = time.time()\n","print(\"\\nTime for Loading all models\", time3 - time2)\n","\n","\n","# Get input and output tensors.\n","#TFLite\n","input_details = interpreter.get_input_details()\n","output_details = interpreter.get_output_details()\n","#Quantized\n","input_details_q = interpreter_q.get_input_details()\n","output_details_q = interpreter_q.get_output_details()\n","\n","#Evaluation\n","#original\n","time4 = time.time()\n","evaluation = original.evaluate(X_test, Y_test)\n","time5 = time.time()\n","print('\\Accuracy of Original : ', evaluation[1])\n","print(\"Total time to predict all\", time5 -time4)\n","print(\"Average time to predict: \", (time5 -time4)/len(X_test))\n","\n","time6 = time.time()\n","n = 0  #count for accuracy\n","normal = []\n","# Test model on input data.\n","for i in range(1, len(X_test)):\n","  test_image = np.expand_dims(X_test[i], axis=0).astype(np.float32)\n","  interpreter.set_tensor(input_details[0]['index'], test_image)\n","  interpreter.invoke()\n","\n","  # The function `get_tensor()` returns a copy of the tensor data.\n","  # Use `tensor()` in order to get a pointer to the tensor.\n","  output_data = interpreter.get_tensor(output_details[0]['index'])\n","  \n","  if np.argmax(output_data)==np.argmax(Y_test[i]):\n","    n+=1\n","  else:\n","    normal.append(i)\n","\n","time7 = time.time()\n","print('\\n\\nAccuracy of TFLite model= ', n/len(X_test))\n","print(\"Time to predict all \" , len(X_test), \" images is: \", time7-time6)\n","print(\"Average time to predict a image is: \", (time7-time6)/len(X_test))\n","    \n","time8 = time.time()\n","q = 0\n","quantized = []\n","# Test model on input data.\n","for i in range(1, len(X_test)):\n","  test_image = np.expand_dims(X_test[i], axis=0).astype(np.float32)\n","  interpreter_q.set_tensor(input_details_q[0]['index'], test_image)\n","  interpreter_q.invoke()\n","\n","  # The function `get_tensor()` returns a copy of the tensor data.\n","  # Use `tensor()` in order to get a pointer to the tensor.\n","  output_data_q = interpreter_q.get_tensor(output_details_q[0]['index'])\n","\n","\n","  if np.argmax(output_data_q)==np.argmax(Y_test[i]):\n","    q+=1\n","  else:\n","    quantized.append(i)\n","\n","time9 = time.time()\n","print('\\n\\nAccuracy of quantized model= ', q/len(X_test))\n","print(\"Time to predict all \", len(X_test), \" images is: \", time9-time8)\n","print(\"Average time to predict a image is: \", (time9-time8)/len(X_test))\n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["2.4.0\n","2.4.0\n","All packages are imported\n","Test images reading is done\n","Number of Test images 193\n","Time for reading and Preprocessing 0.6022207736968994\n","Average time for reading and pre-processing 0.0031203148896212403\n","\n","Time for Loading all models 0.18079876899719238\n","7/7 [==============================] - 0s 15ms/step - loss: 0.6870 - accuracy: 0.9067\n","\\Accuracy of Original :  0.9067357778549194\n","Total time to predict all 0.36591219902038574\n","Average time to predict:  0.0018959181296393044\n","\n","\n","Accuracy of TFLite model=  0.9015544041450777\n","Time to predict all  193  images is:  0.8111746311187744\n","Average time to predict a image is:  0.004202977363309712\n","\n","\n","Accuracy of quantized model=  0.8911917098445595\n","Time to predict all  193  images is:  2.3139142990112305\n","Average time to predict a image is:  0.011989193259125546\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iYkJUjvf4uv1"},"source":["**Spark**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UW2zoiGc401r","executionInfo":{"status":"ok","timestamp":1610287880372,"user_tz":-330,"elapsed":126365,"user":{"displayName":"Arindam Majee","photoUrl":"","userId":"08922294135040060764"}},"outputId":"effcc3fb-81f7-48fd-ff2b-56ebf8013864"},"source":["#PUt the paths here.\n","test_data = '/content/drive/MyDrive/Brain Cancer/Test Data for RPi'\n","original_model = '/content/drive/MyDrive/Brain Cancer/v3/spark.h5'\n","tflite_model = '/content/drive/MyDrive/Brain Cancer/v3/spark_TFLite.tflite'\n","tflite_model_quantized = '/content/drive/MyDrive/Brain Cancer/v3/spark_Quantized.tflite'\n","\n","\n","#Imort the packages\n","import time\n","import tensorflow as tf\n","from tensorflow import keras\n","print(tf.__version__)\n","print(tf.keras.__version__)    \n","#Output must be \n","#2.3.0\n","#2.4.0\n","import numpy as np\n","import cv2\n","import  os\n","from sklearn.preprocessing import OneHotEncoder\n","print('All packages are imported')\n","\n","def read_image(im_path):\n","  img = cv2.imread(im_path,0)\n","  img = cv2.resize(img,(240,240))\n","  return img\n","  \n","  \n","time0 = time.time()\n","x_test, y_test = [], []\n","list_folder=os.listdir(path = test_data)\n","for i in list_folder:\n","  new_path=os.path.join(test_data,i) \n","  pic_list=os.listdir(new_path)                                              \n","  for img in pic_list:  \n","    im_path = os.path.join(new_path,img)\n","    image = read_image(im_path)\n","    if i == 'flair':\n","      label = 0\n","    elif i == 't1':\n","      label = 1\n","    elif i == 't1ce':\n","      label = 2\n","    elif i == 't2':\n","      label = 3\n","    x_test.append(image) \n","    y_test.append(label) \n","\n","print(\"Test images reading is done\")\n","X_test = np.array(x_test).reshape(-1,240,240,1)\n","X_test = X_test/255\n","y_test = np.array(y_test).reshape(-1,1)\n","encoder = OneHotEncoder()\n","y_test = encoder.fit_transform(y_test)\n","Y_test = y_test.toarray()\n","time1 = time.time()\n","print(\"Test images reading is done\")\n","print(\"Number of Test images\",X_test.shape[0])\n","print(\"Time for reading and Preprocessing\", time1 - time0)\n","print(\"Average time for reading and pre-processing\", (time1-time0)/X_test.shape[0])\n","\n","\n","#Read the models\n","# Initialize TFLite interpreter using the model.\n","# Load TFLite model and allocate tensors.\n","time2 = time.time()\n","#original\n","original = tf.keras.models.load_model(original_model)\n","#TFLite\n","interpreter = tf.lite.Interpreter(model_path=tflite_model)\n","interpreter.allocate_tensors()\n","#quantized\n","interpreter_q = tf.lite.Interpreter(model_path=tflite_model_quantized)\n","interpreter_q.allocate_tensors()\n","time3 = time.time()\n","print(\"\\nTime for Loading all models\", time3 - time2)\n","\n","\n","# Get input and output tensors.\n","#TFLite\n","input_details = interpreter.get_input_details()\n","output_details = interpreter.get_output_details()\n","#Quantized\n","input_details_q = interpreter_q.get_input_details()\n","output_details_q = interpreter_q.get_output_details()\n","\n","#Evaluation\n","#original\n","time4 = time.time()\n","evaluation = original.evaluate(X_test, Y_test)\n","time5 = time.time()\n","print('\\nAccuracy of Original : ', evaluation[1])\n","print(\"Total time to predict all\", time5 -time4)\n","print(\"Average time to predict\", (time5 -time4)/len(X_test))\n","\n","time6 = time.time()\n","n = 0  #count for accuracy\n","normal = []\n","# Test model on input data.\n","for i in range(1, len(X_test)):\n","  test_image = np.expand_dims(X_test[i], axis=0).astype(np.float32)\n","  interpreter.set_tensor(input_details[0]['index'], test_image)\n","  interpreter.invoke()\n","\n","  # The function `get_tensor()` returns a copy of the tensor data.\n","  # Use `tensor()` in order to get a pointer to the tensor.\n","  output_data = interpreter.get_tensor(output_details[0]['index'])\n","  \n","  if np.argmax(output_data)==np.argmax(Y_test[i]):\n","    n+=1\n","  else:\n","    normal.append(i)\n","\n","time7 = time.time()\n","print('\\n\\nAccuracy of TFLite model= ', n/len(X_test))\n","print(\"Time to predict all \" , len(X_test), \" images is: \", time7-time6)\n","print(\"Average time to predict a image is: \", (time7-time6)/len(X_test))\n","    \n","time8 = time.time()\n","q = 0\n","quantized = []\n","# Test model on input data.\n","for i in range(1, len(X_test)):\n","  test_image = np.expand_dims(X_test[i], axis=0).astype(np.float32)\n","  interpreter_q.set_tensor(input_details_q[0]['index'], test_image)\n","  interpreter_q.invoke()\n","\n","  # The function `get_tensor()` returns a copy of the tensor data.\n","  # Use `tensor()` in order to get a pointer to the tensor.\n","  output_data_q = interpreter_q.get_tensor(output_details_q[0]['index'])\n","\n","\n","  if np.argmax(output_data_q)==np.argmax(Y_test[i]):\n","    q+=1\n","  else:\n","    quantized.append(i)\n","\n","time9 = time.time()\n","print('\\n\\nAccuracy of quantized model= ', q/len(X_test))\n","print(\"Time to predict all \", len(X_test), \" images is: \", time8-time9)\n","print(\"Average time to predict a image is: \", (time9-time8)/len(X_test))\n","print(\"Everything done!\")"],"execution_count":7,"outputs":[{"output_type":"stream","text":["2.4.0\n","2.4.0\n","All packages are imported\n","Test images reading is done\n","Test images reading is done\n","Number of Test images 193\n","Time for reading and Preprocessing 0.593869686126709\n","Average time for reading and pre-processing 0.0030770450058378706\n","\n","Time for Loading all models 5.297996282577515\n","7/7 [==============================] - 1s 60ms/step - loss: 0.5963 - accuracy: 0.9275\n","\n","Accuracy of Original :  0.9274611473083496\n","Total time to predict all 0.9594881534576416\n","Average time to predict 0.0049714412096250864\n","\n","\n","Accuracy of normal model=  0.9222797927461139\n","Time to predict all  193  images is:  6.057547092437744\n","Average time to predict a image is:  0.0313862543649624\n","\n","\n","Accuracy of quantized model=  0.9222797927461139\n","Time to predict all  193  images is:  -84.86572670936584\n","Average time to predict a image is:  0.43971879124023755\n","Everything done!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PMCjyokUP5KQ"},"source":["**DWT_L6_Reconstruction**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rvVXnsyfFKcr","executionInfo":{"status":"ok","timestamp":1610287896085,"user_tz":-330,"elapsed":142066,"user":{"displayName":"Arindam Majee","photoUrl":"","userId":"08922294135040060764"}},"outputId":"14cc9526-e631-4373-b09d-f1b884dbd3b0"},"source":["#PUt the paths here.\n","test_data = '/content/drive/MyDrive/Brain Cancer/Test Data for RPi'\n","original_model = '/content/drive/MyDrive/Brain Cancer/v3/DWT_Recons_L6.h5'\n","tflite_model = '/content/drive/MyDrive/Brain Cancer/v3/DWT_Recons_L6_TFLite.tflite'\n","tflite_model_quantized = '/content/drive/MyDrive/Brain Cancer/v3/DWT_Recons_L6_TFLite_Quantized.tflite'\n","\n","\n","#Imort the packages\n","import time\n","import tensorflow as tf\n","from tensorflow import keras\n","print(tf.__version__)\n","print(tf.keras.__version__)    \n","#Output must be \n","#2.3.0\n","#2.4.0\n","import numpy as np\n","import cv2,pywt\n","import  os\n","from sklearn.preprocessing import OneHotEncoder\n","print('All packages are imported')\n","\n","def read_image(im_path, level=8):\n","  img = cv2.imread(im_path,0)\n","  img = cv2.resize(img,(256,256))\n","  out = np.zeros((256,256))\n","  for i in range(0,8):\n","    row = img.shape[0]\n","    col = img.shape[1]\n","    cA,(cH,cV,cD) = pywt.dwt2(img,'haar')\n","    out[0:(row//2),0:(col//2)] = cA\n","    out[0:(row//2),(col//2):col] = cH\n","    out[(row//2):row,0:(col//2)] = cV\n","    out[(row//2):row,(col//2):col] = cD\n","    img = cA\n","    \n","  #out[0,0] = 0\n","  out[0:(row//2),0:(col//2)] = 0\n","\n","  for j in range(0,6):\n","    row = img.shape[0]\n","    col = img.shape[1]\n","    cA = out[0:row,0:col]\n","    cH = out[0:row,col:2*col]\n","    cV = out[row:2*row,0:col]\n","    cD = out[row:2*row,col:2*col]\n","    img = pywt.idwt2((cA,(cH,cV,cD)),'haar')\n","    out[0:2*row,0:2*col] = img\n","    \n","\n","  return img\n","  \n","  \n","time0 = time.time()\n","x_test, y_test = [], []\n","list_folder=os.listdir(path = test_data)\n","for i in list_folder:\n","  new_path=os.path.join(test_data,i) \n","  pic_list=os.listdir(new_path)                                              \n","  for img in pic_list:  \n","    im_path = os.path.join(new_path,img)\n","    im_dwt = read_image(im_path)\n","    if i == 'flair':\n","      label = 0\n","    elif i == 't1':\n","      label = 1\n","    elif i == 't1ce':\n","      label = 2\n","    elif i == 't2':\n","      label = 3\n","    x_test.append(im_dwt) \n","    y_test.append(label) \n","\n","print(\"Test images reading is done\")\n","X_test = np.array(x_test).reshape(-1,64,64,1)\n","X_test = X_test/255\n","y_test = np.array(y_test).reshape(-1,1)\n","y_test = encoder.fit_transform(y_test)\n","Y_test = y_test.toarray()\n","time1 = time.time()\n","print(\"Test images reading is done\")\n","print(\"Number of Test images\",X_test.shape[0])\n","print(\"Time for reading and Preprocessing\", time1 - time0)\n","print(\"Average time for reading and pre-processing\", (time1-time0)/X_test.shape[0])\n","\n","\n","#Read the models\n","# Initialize TFLite interpreter using the model.\n","# Load TFLite model and allocate tensors.\n","time2 = time.time()\n","#original\n","original = tf.keras.models.load_model(original_model)\n","#TFLite\n","interpreter = tf.lite.Interpreter(model_path=tflite_model)\n","interpreter.allocate_tensors()\n","#quantized\n","interpreter_q = tf.lite.Interpreter(model_path=tflite_model_quantized)\n","interpreter_q.allocate_tensors()\n","time3 = time.time()\n","print(\"\\nTime for Loading all models\", time3 - time2)\n","\n","\n","# Get input and output tensors.\n","#TFLite\n","input_details = interpreter.get_input_details()\n","output_details = interpreter.get_output_details()\n","#Quantized\n","input_details_q = interpreter_q.get_input_details()\n","output_details_q = interpreter_q.get_output_details()\n","\n","#Evaluation\n","#original\n","time4 = time.time()\n","evaluation = original.evaluate(X_test, Y_test)\n","time5 = time.time()\n","print('\\nAccuracy of Original : ', evaluation[1])\n","print(\"Total time to predict all\", time5 -time4)\n","print(\"Average time to predict\", (time5 -time4)/len(X_test))\n","\n","time6 = time.time()\n","n = 0  #count for accuracy\n","normal = []\n","# Test model on input data.\n","for i in range(1, len(X_test)):\n","  test_image = np.expand_dims(X_test[i], axis=0).astype(np.float32)\n","  interpreter.set_tensor(input_details[0]['index'], test_image)\n","  interpreter.invoke()\n","\n","  # The function `get_tensor()` returns a copy of the tensor data.\n","  # Use `tensor()` in order to get a pointer to the tensor.\n","  output_data = interpreter.get_tensor(output_details[0]['index'])\n","  \n","  if np.argmax(output_data)==np.argmax(Y_test[i]):\n","    n+=1\n","  else:\n","    normal.append(i)\n","\n","time7 = time.time()\n","print('\\n\\nAccuracy of normal model= ', n/len(X_test))\n","print(\"Time to predict all \" , len(X_test), \" images is: \", time7-time6)\n","print(\"Average time to predict a image is: \", (time7-time6)/len(X_test))\n","    \n","time8 = time.time()\n","q = 0\n","quantized = []\n","# Test model on input data.\n","for i in range(1, len(X_test)):\n","  test_image = np.expand_dims(X_test[i], axis=0).astype(np.float32)\n","  interpreter_q.set_tensor(input_details_q[0]['index'], test_image)\n","  interpreter_q.invoke()\n","\n","  # The function `get_tensor()` returns a copy of the tensor data.\n","  # Use `tensor()` in order to get a pointer to the tensor.\n","  output_data_q = interpreter_q.get_tensor(output_details_q[0]['index'])\n","\n","\n","  if np.argmax(output_data_q)==np.argmax(Y_test[i]):\n","    q+=1\n","  else:\n","    quantized.append(i)\n","\n","time9 = time.time()\n","print('\\n\\nAccuracy of quantized model= ', q/len(X_test))\n","print(\"Time to predict all \", len(X_test), \" images is: \", time9-time8)\n","print(\"Average time to predict a image is: \", (time9-time8)/len(X_test))\n","print(\"Everything done!\")"],"execution_count":8,"outputs":[{"output_type":"stream","text":["2.4.0\n","2.4.0\n","All packages are imported\n","Test images reading is done\n","Test images reading is done\n","Number of Test images 193\n","Time for reading and Preprocessing 1.1093683242797852\n","Average time for reading and pre-processing 0.005748022405594742\n","\n","Time for Loading all models 6.634419918060303\n","7/7 [==============================] - 0s 13ms/step - loss: 0.2709 - accuracy: 0.9171\n","\n","Accuracy of Original :  0.9170984625816345\n","Total time to predict all 0.31792163848876953\n","Average time to predict 0.0016472623755894795\n","\n","\n","Accuracy of normal model=  0.9119170984455959\n","Time to predict all  193  images is:  0.6785969734191895\n","Average time to predict a image is:  0.0035160464943999456\n","\n","\n","Accuracy of quantized model=  0.9119170984455959\n","Time to predict all  193  images is:  6.576596736907959\n","Average time to predict a image is:  0.034075630761181135\n","Everything done!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ckNaVar4Poqw"},"source":["**DWT + Spark**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"okBHUwfLMan1","executionInfo":{"status":"ok","timestamp":1610287903082,"user_tz":-330,"elapsed":149055,"user":{"displayName":"Arindam Majee","photoUrl":"","userId":"08922294135040060764"}},"outputId":"91dfd1e3-44b7-4925-fa6b-bfd535361235"},"source":["#PUt the paths here.\n","test_data = '/content/drive/MyDrive/Brain Cancer/Test Data for RPi'\n","original_model = '/content/drive/MyDrive/Brain Cancer/v3/dwt_spark.h5'\n","tflite_model = '/content/drive/MyDrive/Brain Cancer/v3/dwt_spark_tflite.tflite'\n","tflite_model_quantized = '/content/drive/MyDrive/Brain Cancer/v3/dwt_spark_quantized.tflite'\n","\n","\n","#Imort the packages\n","import time\n","import tensorflow as tf\n","from tensorflow import keras\n","print(tf.__version__)\n","print(tf.keras.__version__)    \n","#Output must be \n","#2.3.0\n","#2.4.0\n","import numpy as np\n","import cv2\n","import  os\n","from sklearn.preprocessing import OneHotEncoder\n","import pywt\n","print('All packages are imported')\n","\n","\n","def read_image(im_path):\n","  img = cv2.imread(im_path,0)\n","  img = cv2.resize(img,(240,240))\n","  return img\n","  \n","  \n","time0 = time.time()\n","x_test, y_test = [], []\n","list_folder=os.listdir(path = test_data)\n","for i in list_folder:\n","  new_path=os.path.join(test_data,i) \n","  pic_list=os.listdir(new_path)                                              \n","  for img in pic_list:  \n","    im_path = os.path.join(new_path,img)\n","    image = read_image(im_path)\n","    cA, _ = pywt.dwt2(image,'db2')    #Performing DWT operation\n","    if i == 'flair':\n","      label = 0\n","    elif i == 't1':\n","      label = 1\n","    elif i == 't1ce':\n","      label = 2\n","    elif i == 't2':\n","      label = 3\n","    x_test.append(cA) \n","    y_test.append(label) \n","\n","\n","X_test = np.array(x_test).reshape(-1,121,121,1)\n","X_test = X_test/255\n","y_test = np.array(y_test).reshape(-1,1)\n","encoder = OneHotEncoder()\n","y_test = encoder.fit_transform(y_test)\n","Y_test = y_test.toarray()\n","time1 = time.time()\n","print(\"Test images reading is done\")\n","print(\"Number of Test images\",X_test.shape[0])\n","print(\"Time for reading and Preprocessing\", time1 - time0)\n","print(\"Average time for reading and pre-processing\", (time1-time0)/X_test.shape[0])\n","\n","\n","#Read the models\n","# Initialize TFLite interpreter using the model.\n","# Load TFLite model and allocate tensors.\n","time2 = time.time()\n","#original\n","original = tf.keras.models.load_model(original_model)\n","#TFLite\n","interpreter = tf.lite.Interpreter(model_path=tflite_model)\n","interpreter.allocate_tensors()\n","#quantized\n","interpreter_q = tf.lite.Interpreter(model_path=tflite_model_quantized)\n","interpreter_q.allocate_tensors()\n","time3 = time.time()\n","print(\"\\nTime for Loading all models\", time3 - time2)\n","\n","\n","# Get input and output tensors.\n","#TFLite\n","input_details = interpreter.get_input_details()\n","output_details = interpreter.get_output_details()\n","#Quantized\n","input_details_q = interpreter_q.get_input_details()\n","output_details_q = interpreter_q.get_output_details()\n","\n","#Evaluation\n","#original\n","time4 = time.time()\n","evaluation = original.evaluate(X_test, Y_test)\n","time5 = time.time()\n","print('\\Accuracy of Original : ', evaluation[1])\n","print(\"Total time to predict all\", time5 -time4)\n","print(\"Average time to predict: \", (time5 -time4)/len(X_test))\n","\n","time6 = time.time()\n","n = 0  #count for accuracy\n","normal = []\n","# Test model on input data.\n","for i in range(1, len(X_test)):\n","  test_image = np.expand_dims(X_test[i], axis=0).astype(np.float32)\n","  interpreter_q.set_tensor(input_details_q[0]['index'], test_image)\n","  interpreter.invoke()\n","\n","  # The function `get_tensor()` returns a copy of the tensor data.\n","  # Use `tensor()` in order to get a pointer to the tensor.\n","  output_data = interpreter.get_tensor(output_details[0]['index'])\n","  \n","  if np.argmax(output_data)==np.argmax(Y_test[i]):\n","    n+=1\n","  else:\n","    normal.append(i)\n","\n","time7 = time.time()\n","print('\\n\\nAccuracy of normal model= ', n/len(X_test))\n","print(\"Time to predict all \" , len(X_test), \" images is: \", time7-time6)\n","print(\"Average time to predict a image is: \", (time7-time6)/len(X_test))\n","    \n","time8 = time.time()\n","q = 0\n","quantized = []\n","# Test model on input data.\n","for i in range(1, len(X_test)):\n","  test_image = np.expand_dims(X_test[i], axis=0).astype(np.float32)\n","  interpreter_q.set_tensor(input_details_q[0]['index'], test_image)\n","  interpreter_q.invoke()\n","\n","  # The function `get_tensor()` returns a copy of the tensor data.\n","  # Use `tensor()` in order to get a pointer to the tensor.\n","  output_data_q = interpreter_q.get_tensor(output_details_q[0]['index'])\n","\n","\n","  if np.argmax(output_data_q)==np.argmax(Y_test[i]):\n","    q+=1\n","  else:\n","    quantized.append(i)\n","\n","time9 = time.time()\n","print('\\n\\nAccuracy of quantized model= ', q/len(X_test))\n","print(\"Time to predict all \", len(X_test), \" images is: \", time9-time8)\n","print(\"Average time to predict a image is: \", (time9-time8)/len(X_test))\n"],"execution_count":9,"outputs":[{"output_type":"stream","text":["2.4.0\n","2.4.0\n","All packages are imported\n","Test images reading is done\n","Number of Test images 193\n","Time for reading and Preprocessing 0.8160793781280518\n","Average time for reading and pre-processing 0.0042283905602489725\n","\n","Time for Loading all models 1.5825834274291992\n","7/7 [==============================] - 0s 16ms/step - loss: 0.1102 - accuracy: 0.9637\n","\\Accuracy of Original :  0.9637305736541748\n","Total time to predict all 0.39378809928894043\n","Average time to predict:  0.002040352846056686\n","\n","\n","Accuracy of normal model=  0.24352331606217617\n","Time to predict all  193  images is:  0.7238483428955078\n","Average time to predict a image is:  0.0037505095486813876\n","\n","\n","Accuracy of quantized model=  0.9585492227979274\n","Time to predict all  193  images is:  3.6732611656188965\n","Average time to predict a image is:  0.019032441272636768\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZPNGU1XAC1Ce"},"source":["**DWT Reconstruction L7**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_1xQMwBXC1SZ","executionInfo":{"status":"ok","timestamp":1610287987154,"user_tz":-330,"elapsed":233120,"user":{"displayName":"Arindam Majee","photoUrl":"","userId":"08922294135040060764"}},"outputId":"9554da45-077f-4f8e-b556-7c551a9c1322"},"source":["#PUt the paths here.\n","test_data = '/content/drive/MyDrive/Brain Cancer/Test Data for RPi'\n","original_model = '/content/drive/MyDrive/Brain Cancer/v3/DWT_Recons_L7.h5'\n","tflite_model = '/content/drive/MyDrive/Brain Cancer/v3/DWT_Recons_L7_TFLite.tflite'\n","tflite_model_quantized = '/content/drive/MyDrive/Brain Cancer/v3/DWT_Recons_L7_TFLite_Quantized.tflite'\n","\n","\n","#Imort the packages\n","import time\n","import tensorflow as tf\n","from tensorflow import keras\n","print(tf.__version__)\n","print(tf.keras.__version__)    \n","#Output must be \n","#2.3.0\n","#2.4.0\n","import numpy as np\n","import cv2\n","import  os\n","from sklearn.preprocessing import OneHotEncoder\n","import pywt\n","print('All packages are imported')\n","\n","\n","def read_image(im_path, level=8):\n","  img = cv2.imread(im_path,0)\n","  img = cv2.resize(img,(256,256))\n","  out = np.zeros((256,256))\n","  for i in range(0,8):\n","    row = img.shape[0]\n","    col = img.shape[1]\n","    cA,(cH,cV,cD) = pywt.dwt2(img,'haar')\n","    out[0:(row//2),0:(col//2)] = cA\n","    out[0:(row//2),(col//2):col] = cH\n","    out[(row//2):row,0:(col//2)] = cV\n","    out[(row//2):row,(col//2):col] = cD\n","    img = cA\n","    \n","  #out[0,0] = 0\n","  out[0:(row//2),0:(col//2)] = 0\n","\n","  for j in range(0,7):\n","    row = img.shape[0]\n","    col = img.shape[1]\n","    cA = out[0:row,0:col]\n","    cH = out[0:row,col:2*col]\n","    cV = out[row:2*row,0:col]\n","    cD = out[row:2*row,col:2*col]\n","    img = pywt.idwt2((cA,(cH,cV,cD)),'haar')\n","    out[0:2*row,0:2*col] = img\n","    \n","\n","  return img\n","\n","\n","time0 = time.time()\n","x_test, y_test = [], []\n","list_folder=os.listdir(path = test_data)\n","for i in list_folder:\n","  new_path=os.path.join(test_data,i) \n","  pic_list=os.listdir(new_path)                                              \n","  for img in pic_list:  \n","    im_path = os.path.join(new_path,img)\n","    im_dwt = read_image(im_path)\n","    if i == 'flair':\n","      label = 0\n","    elif i == 't1':\n","      label = 1\n","    elif i == 't1ce':\n","      label = 2\n","    elif i == 't2':\n","      label = 3\n","    x_test.append(im_dwt) \n","    y_test.append(label) \n","\n","print(\"Test images reading is done\")\n","X_test = np.array(x_test).reshape(-1,128,128,1)\n","X_test = X_test/255\n","y_test = np.array(y_test).reshape(-1,1)\n","y_test = encoder.fit_transform(y_test)\n","Y_test = y_test.toarray()\n","time1 = time.time()\n","print(\"Test images reading is done\")\n","print(\"Number of Test images\",X_test.shape[0])\n","print(\"Time for reading and Preprocessing\", time1 - time0)\n","print(\"Average time for reading and pre-processing\", (time1-time0)/X_test.shape[0])\n","\n","\n","#Read the models\n","# Initialize TFLite interpreter using the model.\n","# Load TFLite model and allocate tensors.\n","time2 = time.time()\n","#original\n","original = tf.keras.models.load_model(original_model)\n","#TFLite\n","interpreter = tf.lite.Interpreter(model_path=tflite_model)\n","interpreter.allocate_tensors()\n","#quantized\n","interpreter_q = tf.lite.Interpreter(model_path=tflite_model_quantized)\n","interpreter_q.allocate_tensors()\n","time3 = time.time()\n","print(\"\\nTime for Loading all models\", time3 - time2)\n","\n","\n","# Get input and output tensors.\n","#TFLite\n","input_details = interpreter.get_input_details()\n","output_details = interpreter.get_output_details()\n","#Quantized\n","input_details_q = interpreter_q.get_input_details()\n","output_details_q = interpreter_q.get_output_details()\n","\n","#Evaluation\n","#original\n","time4 = time.time()\n","evaluation = original.evaluate(X_test, Y_test)\n","time5 = time.time()\n","print('\\nAccuracy of Original : ', evaluation[1])\n","print(\"Total time to predict all\", time5 -time4)\n","print(\"Average time to predict\", (time5 -time4)/len(X_test))\n","\n","time6 = time.time()\n","n = 0  #count for accuracy\n","normal = []\n","# Test model on input data.\n","for i in range(1, len(X_test)):\n","  test_image = np.expand_dims(X_test[i], axis=0).astype(np.float32)\n","  interpreter.set_tensor(input_details[0]['index'], test_image)\n","  interpreter.invoke()\n","\n","  # The function `get_tensor()` returns a copy of the tensor data.\n","  # Use `tensor()` in order to get a pointer to the tensor.\n","  output_data = interpreter.get_tensor(output_details[0]['index'])\n","  \n","  if np.argmax(output_data)==np.argmax(Y_test[i]):\n","    n+=1\n","  else:\n","    normal.append(i)\n","\n","time7 = time.time()\n","print('\\n\\nAccuracy of TFLite model= ', n/len(X_test))\n","print(\"Time to predict all \" , len(X_test), \" images is: \", time7-time6)\n","print(\"Average time to predict a image is: \", (time7-time6)/len(X_test))\n","    \n","time8 = time.time()\n","q = 0\n","quantized = []\n","# Test model on input data.\n","for i in range(1, len(X_test)):\n","  test_image = np.expand_dims(X_test[i], axis=0).astype(np.float32)\n","  interpreter_q.set_tensor(input_details_q[0]['index'], test_image)\n","  interpreter_q.invoke()\n","\n","  # The function `get_tensor()` returns a copy of the tensor data.\n","  # Use `tensor()` in order to get a pointer to the tensor.\n","  output_data_q = interpreter_q.get_tensor(output_details_q[0]['index'])\n","\n","\n","  if np.argmax(output_data_q)==np.argmax(Y_test[i]):\n","    q+=1\n","  else:\n","    quantized.append(i)\n","\n","time9 = time.time()\n","print('\\n\\nAccuracy of quantized model= ', q/len(X_test))\n","print(\"Time to predict all \", len(X_test), \" images is: \", time9-time8)\n","print(\"Average time to predict a image is: \", (time9-time8)/len(X_test))\n","print(\"Everything done!\")"],"execution_count":10,"outputs":[{"output_type":"stream","text":["2.4.0\n","2.4.0\n","All packages are imported\n","Test images reading is done\n","Test images reading is done\n","Number of Test images 193\n","Time for reading and Preprocessing 1.1251811981201172\n","Average time for reading and pre-processing 0.005829954394404752\n","\n","Time for Loading all models 11.373985290527344\n","7/7 [==============================] - 0s 13ms/step - loss: 0.1753 - accuracy: 0.9430\n","\n","Accuracy of Original :  0.9430052042007446\n","Total time to predict all 0.30805468559265137\n","Average time to predict 0.0015961382673194372\n","\n","\n","Accuracy of TFLite model=  0.9378238341968912\n","Time to predict all  193  images is:  1.756357192993164\n","Average time to predict a image is:  0.009100296336752146\n","\n","\n","Accuracy of quantized model=  0.9430051813471503\n","Time to predict all  193  images is:  69.2361581325531\n","Average time to predict a image is:  0.35873657063499015\n","Everything done!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"364AEO5gE8Gz"},"source":["**DWT Reconstruction**"]},{"cell_type":"code","metadata":{"id":"R7rTyWjXE4YB"},"source":["#PUt the paths here.\n","test_data = '/content/drive/MyDrive/Brain Cancer/Test Data for RPi'\n","original_model = '/content/drive/MyDrive/Brain Cancer/v3/DWT_Reconstruction.h5'\n","tflite_model = '/content/drive/MyDrive/Brain Cancer/v3/DWT_Reconstruction_TFLite.tflite'\n","tflite_model_quantized = '/content/drive/MyDrive/Brain Cancer/v3/DWT_Reconstruction_TFLite_Quantized.tflite'\n","\n","\n","#Imort the packages\n","import time\n","import tensorflow as tf\n","from tensorflow import keras\n","print(tf.__version__)\n","print(tf.keras.__version__)    \n","#Output must be \n","#2.3.0\n","#2.4.0\n","import numpy as np\n","import cv2\n","import  os\n","from sklearn.preprocessing import OneHotEncoder\n","import pywt\n","print('All packages are imported')\n","\n","\n","def read_image(im_path, level=8):\n","  img = cv2.imread(im_path,0)\n","  img = cv2.resize(img,(256,256))\n","  out = np.zeros((256,256))\n","  for i in range(0,8):\n","    row = img.shape[0]\n","    col = img.shape[1]\n","    cA,(cH,cV,cD) = pywt.dwt2(img,'haar')\n","    out[0:(row//2),0:(col//2)] = cA\n","    out[0:(row//2),(col//2):col] = cH\n","    out[(row//2):row,0:(col//2)] = cV\n","    out[(row//2):row,(col//2):col] = cD\n","    img = cA\n","    \n","  #out[0,0] = 0\n","  out[0:(row//2),0:(col//2)] = 0\n","\n","  for j in range(0,8):\n","    row = img.shape[0]\n","    col = img.shape[1]\n","    cA = out[0:row,0:col]\n","    cH = out[0:row,col:2*col]\n","    cV = out[row:2*row,0:col]\n","    cD = out[row:2*row,col:2*col]\n","    img = pywt.idwt2((cA,(cH,cV,cD)),'haar')\n","    out[0:2*row,0:2*col] = img\n","    \n","\n","  return img\n","\n","\n","time0 = time.time()\n","x_test, y_test = [], []\n","list_folder=os.listdir(path = test_data)\n","for i in list_folder:\n","  new_path=os.path.join(test_data,i) \n","  pic_list=os.listdir(new_path)                                              \n","  for img in pic_list:  \n","    im_path = os.path.join(new_path,img)\n","    im_dwt = read_image(im_path)\n","    if i == 'flair':\n","      label = 0\n","    elif i == 't1':\n","      label = 1\n","    elif i == 't1ce':\n","      label = 2\n","    elif i == 't2':\n","      label = 3\n","    x_test.append(im_dwt) \n","    y_test.append(label) \n","\n","print(\"Test images reading is done\")\n","X_test = np.array(x_test).reshape(-1,256,256,1)\n","X_test = X_test/255\n","y_test = np.array(y_test).reshape(-1,1)\n","y_test = encoder.fit_transform(y_test)\n","Y_test = y_test.toarray()\n","time1 = time.time()\n","print(\"Test images reading is done\")\n","print(\"Number of Test images\",X_test.shape[0])\n","print(\"Time for reading and Preprocessing\", time1 - time0)\n","print(\"Average time for reading and pre-processing\", (time1-time0)/X_test.shape[0])\n","\n","\n","#Read the models\n","# Initialize TFLite interpreter using the model.\n","# Load TFLite model and allocate tensors.\n","time2 = time.time()\n","#original\n","original = tf.keras.models.load_model(original_model)\n","#TFLite\n","interpreter = tf.lite.Interpreter(model_path=tflite_model)\n","interpreter.allocate_tensors()\n","#quantized\n","interpreter_q = tf.lite.Interpreter(model_path=tflite_model_quantized)\n","interpreter_q.allocate_tensors()\n","time3 = time.time()\n","print(\"\\nTime for Loading all models\", time3 - time2)\n","\n","\n","# Get input and output tensors.\n","#TFLite\n","input_details = interpreter.get_input_details()\n","output_details = interpreter.get_output_details()\n","#Quantized\n","input_details_q = interpreter_q.get_input_details()\n","output_details_q = interpreter_q.get_output_details()\n","\n","#Evaluation\n","#original\n","time4 = time.time()\n","evaluation = original.evaluate(X_test, Y_test)\n","time5 = time.time()\n","print('\\nAccuracy of Original : ', evaluation[1])\n","print(\"Total time to predict all\", time5 -time4)\n","print(\"Average time to predict\", (time5 -time4)/len(X_test))\n","\n","time6 = time.time()\n","n = 0  #count for accuracy\n","normal = []\n","# Test model on input data.\n","for i in range(1, len(X_test)):\n","  test_image = np.expand_dims(X_test[i], axis=0).astype(np.float32)\n","  interpreter.set_tensor(input_details[0]['index'], test_image)\n","  interpreter.invoke()\n","\n","  # The function `get_tensor()` returns a copy of the tensor data.\n","  # Use `tensor()` in order to get a pointer to the tensor.\n","  output_data = interpreter.get_tensor(output_details[0]['index'])\n","  \n","  if np.argmax(output_data)==np.argmax(Y_test[i]):\n","    n+=1\n","  else:\n","    normal.append(i)\n","\n","time7 = time.time()\n","print('\\n\\nAccuracy of TFLite model= ', n/len(X_test))\n","print(\"Time to predict all \" , len(X_test), \" images is: \", time7-time6)\n","print(\"Average time to predict a image is: \", (time7-time6)/len(X_test))\n","    \n","time8 = time.time()\n","q = 0\n","quantized = []\n","# Test model on input data.\n","for i in range(1, len(X_test)):\n","  test_image = np.expand_dims(X_test[i], axis=0).astype(np.float32)\n","  interpreter_q.set_tensor(input_details_q[0]['index'], test_image)\n","  interpreter_q.invoke()\n","\n","  # The function `get_tensor()` returns a copy of the tensor data.\n","  # Use `tensor()` in order to get a pointer to the tensor.\n","  output_data_q = interpreter_q.get_tensor(output_details_q[0]['index'])\n","\n","\n","  if np.argmax(output_data_q)==np.argmax(Y_test[i]):\n","    q+=1\n","  else:\n","    quantized.append(i)\n","\n","time9 = time.time()\n","print('\\n\\nAccuracy of quantized model= ', q/len(X_test))\n","print(\"Time to predict all \", len(X_test), \" images is: \", time9-time8)\n","print(\"Average time to predict a image is: \", (time9-time8)/len(X_test))\n","print(\"Everything done!\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UPn7sXnGCwZW"},"source":["**Normal**"]},{"cell_type":"code","metadata":{"id":"NzdqJ80lCvUp"},"source":["#PUt the paths here.\n","test_data = '/content/drive/MyDrive/Brain Cancer/Test Data for RPi'\n","original_model = '/content/drive/MyDrive/Brain Cancer/v2/Normal_tensorflow.h5'\n","tflite_model = '/content/drive/MyDrive/Brain Cancer/v2/Normal_TFLite.tflite'\n","tflite_model_quantized = '/content/drive/MyDrive/Brain Cancer/v2/Normal_Quantized_TFLite.tflite'\n","\n","\n","#Imort the packages\n","import time\n","import tensorflow as tf\n","from tensorflow import keras\n","print(tf.__version__)\n","print(tf.keras.__version__)    \n","#Output must be \n","#2.3.0\n","#2.4.0\n","import numpy as np\n","import cv2\n","import  os\n","from sklearn.preprocessing import OneHotEncoder\n","print('All packages are imported')\n","\n","def read_image(im_path):\n","  img = cv2.imread(im_path)\n","  img = cv2.resize(img,(240,240))\n","  return img\n","\n","x_test, y_test = [], []\n","list_folder=os.listdir(path = test_data)\n","for i in list_folder:\n","  new_path=os.path.join(test_data,i) \n","  pic_list=os.listdir(new_path)                                              \n","  for img in pic_list:  \n","    im_path = os.path.join(new_path,img)\n","    image = read_image(im_path)\n","    if i == 'flair':\n","      label = 0\n","    elif i == 't1':\n","      label = 1\n","    elif i == 't1ce':\n","      label = 2\n","    elif i == 't2':\n","      label = 3\n","    x_test.append(image) \n","    y_test.append(label) \n","\n","encoder = OneHotEncoder()\n","print(\"Test images reading is done\")\n","X_test = np.array(x_test).reshape(-1,240,240,3)\n","X_test = X_test/255\n","y_test = np.array(y_test).reshape(-1,1)\n","y_test = encoder.fit_transform(y_test)\n","Y_test = y_test.toarray()\n","time1 = time.time()\n","print(\"Test images reading is done\")\n","print(\"Number of Test images\",X_test.shape[0])\n","print(\"Time for reading and Preprocessing\", time1 - time0)\n","print(\"Average time for reading and pre-processing\", (time1-time0)/X_test.shape[0])\n","\n","\n","#Read the models\n","# Initialize TFLite interpreter using the model.\n","# Load TFLite model and allocate tensors.\n","time2 = time.time()\n","#original\n","original = tf.keras.models.load_model(original_model)\n","#TFLite\n","interpreter = tf.lite.Interpreter(model_path=tflite_model)\n","interpreter.allocate_tensors()\n","#quantized\n","interpreter_q = tf.lite.Interpreter(model_path=tflite_model_quantized)\n","interpreter_q.allocate_tensors()\n","time3 = time.time()\n","print(\"\\nTime for Loading all models\", time3 - time2)\n","\n","\n","# Get input and output tensors.\n","#TFLite\n","input_details = interpreter.get_input_details()\n","output_details = interpreter.get_output_details()\n","#Quantized\n","input_details_q = interpreter_q.get_input_details()\n","output_details_q = interpreter_q.get_output_details()\n","\n","#Evaluation\n","#original\n","time4 = time.time()\n","evaluation = original.evaluate(X_test, Y_test)\n","time5 = time.time()\n","print('\\nAccuracy of Original : ', evaluation[1])\n","print(\"Total time to predict all\", time5 -time4)\n","print(\"Average time to predict\", (time5 -time4)/len(X_test))\n","\n","time6 = time.time()\n","n = 0  #count for accuracy\n","normal = []\n","# Test model on input data.\n","for i in range(1, len(X_test)):\n","  test_image = np.expand_dims(X_test[i], axis=0).astype(np.float32)\n","  interpreter.set_tensor(input_details[0]['index'], test_image)\n","  interpreter.invoke()\n","\n","  # The function `get_tensor()` returns a copy of the tensor data.\n","  # Use `tensor()` in order to get a pointer to the tensor.\n","  output_data = interpreter.get_tensor(output_details[0]['index'])\n","  \n","  if np.argmax(output_data)==np.argmax(Y_test[i]):\n","    n+=1\n","  else:\n","    normal.append(i)\n","\n","time7 = time.time()\n","print('\\n\\nAccuracy of TFLite model= ', n/len(X_test))\n","print(\"Time to predict all \" , len(X_test), \" images is: \", time7-time6)\n","print(\"Average time to predict a image is: \", (time7-time6)/len(X_test))\n","    \n","time8 = time.time()\n","q = 0\n","quantized = []\n","# Test model on input data.\n","for i in range(1, len(X_test)):\n","  test_image = np.expand_dims(X_test[i], axis=0).astype(np.float32)\n","  interpreter_q.set_tensor(input_details_q[0]['index'], test_image)\n","  interpreter_q.invoke()\n","\n","  # The function `get_tensor()` returns a copy of the tensor data.\n","  # Use `tensor()` in order to get a pointer to the tensor.\n","  output_data_q = interpreter_q.get_tensor(output_details_q[0]['index'])\n","\n","\n","  if np.argmax(output_data_q)==np.argmax(Y_test[i]):\n","    q+=1\n","  else:\n","    quantized.append(i)\n","\n","time9 = time.time()\n","print('\\n\\nAccuracy of quantized model= ', q/len(X_test))\n","print(\"Time to predict all \", len(X_test), \" images is: \", time9-time8)\n","print(\"Average time to predict a image is: \", (time9-time8)/len(X_test))\n","print(\"Everything done!\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cLcf17CJE5T4"},"source":["**DWT**"]},{"cell_type":"code","metadata":{"id":"0EDMQr-cE7Pv"},"source":["#PUt the paths here.\n","test_data = '/content/drive/MyDrive/Brain Cancer/Test Data for RPi'\n","original_model = '/content/drive/MyDrive/Brain Cancer/v2/dwt_normal.h5'\n","tflite_model = '/content/drive/MyDrive/Brain Cancer/v2/dwt_tflite.tflite'\n","tflite_model_quantized = '/content/drive/MyDrive/Brain Cancer/v2/dwt_quantized_TFLite.tflite'\n","\n","\n","#Imort the packages\n","import time\n","import tensorflow as tf\n","from tensorflow import keras\n","print(tf.__version__)\n","print(tf.keras.__version__)    \n","#Output must be \n","#2.3.0\n","#2.4.0\n","import numpy as np\n","import cv2,pywt\n","import  os\n","from sklearn.preprocessing import OneHotEncoder\n","print('All packages are imported')\n","\n","def read_image(im_path):\n","  img = cv2.imread(im_path)\n","  img = cv2.resize(img,(240,240))\n","  return img\n","\n","x_test, y_test = [], []\n","list_folder=os.listdir(path = test_data)\n","for i in list_folder:\n","  new_path=os.path.join(test_data,i) \n","  pic_list=os.listdir(new_path)                                              \n","  for img in pic_list:  \n","    im_path = os.path.join(new_path,img)\n","    image = read_image(im_path)\n","    if i == 'flair':\n","      label = 0\n","    elif i == 't1':\n","      label = 1\n","    elif i == 't1ce':\n","      label = 2\n","    elif i == 't2':\n","      label = 3\n","    x_test.append(image) \n","    y_test.append(label) \n","\n","encoder = OneHotEncoder()\n","print(\"Test images reading is done\")\n","X_test = np.array(x_test).reshape(-1,240,240,3)\n","X_test = X_test/255\n","y_test = np.array(y_test).reshape(-1,1)\n","y_test = encoder.fit_transform(y_test)\n","Y_test = y_test.toarray()\n","time1 = time.time()\n","print(\"Test images reading is done\")\n","print(\"Number of Test images\",X_test.shape[0])\n","print(\"Time for reading and Preprocessing\", time1 - time0)\n","print(\"Average time for reading and pre-processing\", (time1-time0)/X_test.shape[0])\n","\n","\n","#Read the models\n","# Initialize TFLite interpreter using the model.\n","# Load TFLite model and allocate tensors.\n","time2 = time.time()\n","#original\n","original = tf.keras.models.load_model(original_model)\n","#TFLite\n","interpreter = tf.lite.Interpreter(model_path=tflite_model)\n","interpreter.allocate_tensors()\n","#quantized\n","interpreter_q = tf.lite.Interpreter(model_path=tflite_model_quantized)\n","interpreter_q.allocate_tensors()\n","time3 = time.time()\n","print(\"\\nTime for Loading all models\", time3 - time2)\n","\n","\n","# Get input and output tensors.\n","#TFLite\n","input_details = interpreter.get_input_details()\n","output_details = interpreter.get_output_details()\n","#Quantized\n","input_details_q = interpreter_q.get_input_details()\n","output_details_q = interpreter_q.get_output_details()\n","\n","#Evaluation\n","#original\n","time4 = time.time()\n","evaluation = original.evaluate(X_test, Y_test)\n","time5 = time.time()\n","print('\\nAccuracy of Original : ', evaluation[1])\n","print(\"Total time to predict all\", time5 -time4)\n","print(\"Average time to predict\", (time5 -time4)/len(X_test))\n","\n","time6 = time.time()\n","n = 0  #count for accuracy\n","normal = []\n","# Test model on input data.\n","for i in range(1, len(X_test)):\n","  test_image = np.expand_dims(X_test[i], axis=0).astype(np.float32)\n","  interpreter.set_tensor(input_details[0]['index'], test_image)\n","  interpreter.invoke()\n","\n","  # The function `get_tensor()` returns a copy of the tensor data.\n","  # Use `tensor()` in order to get a pointer to the tensor.\n","  output_data = interpreter.get_tensor(output_details[0]['index'])\n","  \n","  if np.argmax(output_data)==np.argmax(Y_test[i]):\n","    n+=1\n","  else:\n","    normal.append(i)\n","\n","time7 = time.time()\n","print('\\n\\nAccuracy of TFLite model= ', n/len(X_test))\n","print(\"Time to predict all \" , len(X_test), \" images is: \", time7-time6)\n","print(\"Average time to predict a image is: \", (time7-time6)/len(X_test))\n","    \n","time8 = time.time()\n","q = 0\n","quantized = []\n","# Test model on input data.\n","for i in range(1, len(X_test)):\n","  test_image = np.expand_dims(X_test[i], axis=0).astype(np.float32)\n","  interpreter_q.set_tensor(input_details_q[0]['index'], test_image)\n","  interpreter_q.invoke()\n","\n","  # The function `get_tensor()` returns a copy of the tensor data.\n","  # Use `tensor()` in order to get a pointer to the tensor.\n","  output_data_q = interpreter_q.get_tensor(output_details_q[0]['index'])\n","\n","\n","  if np.argmax(output_data_q)==np.argmax(Y_test[i]):\n","    q+=1\n","  else:\n","    quantized.append(i)\n","\n","time9 = time.time()\n","print('\\n\\nAccuracy of quantized model= ', q/len(X_test))\n","print(\"Time to predict all \", len(X_test), \" images is: \", time9-time8)\n","print(\"Average time to predict a image is: \", (time9-time8)/len(X_test))\n","print(\"Everything done!\")"],"execution_count":null,"outputs":[]}]}